# CosolventAI ↔ Whitepaper Alignment Roadmap

> **Source whitepaper:** `tm-reference_CL4_V4.md` — *Thin Markets: A Deep Dive into Market Physics and Engineering*  
> **Supplemental references:** `tm-reference-supplemental_1_V5.md`, `tm-reference-supplemental_2_V5.md`, `Middle Powers Trade Strategy & AI.md`  
> **Repository assessed:** CosolventAI (this repo)  
> **Date:** 2026-02-18  
> **Author:** Generated by Antigravity Agent for DeeperPoint

---

## Executive Summary

The whitepaper (V4) defines Cosolvent as an **open-source framework for thin market automation** comprising eight core modules (Chapter 32):

1. Semantic matching engine  
2. Trusted intermediary protocol  
3. Multimodal input pipeline  
4. Asynchronous brokerage agents  
5. Memory and context management  
6. Trust gradation framework  
7. Dynamic pricing module  
8. Dispute resolution pipeline  

The whitepaper also introduces two companion initiatives — **ClientSynth** (synthetic user generation for cold-start) and **Digital Twins** (simulated markets combining Cosolvent + ClientSynth) — and frames thin market engineering as a tool of **national economic strategy** (Middle Powers bloc, $37.7T trade diversification).

This roadmap compares every major whitepaper concept against the current CosolventAI codebase to identify alignment gaps and outline the changes needed. It incorporates the team's recent design work (`docs/design/thin_market_framework_v1.md`, `docs/design/admin_interface.md`) and the nascent `participants` / `participant_embeddings` schema evolution.

---

## Table of Contents

1. [Whitepaper Module Inventory vs. Current Implementation](#1-whitepaper-module-inventory-vs-current-implementation)
2. [Market Physics — Domain Model Gaps](#2-market-physics--domain-model-gaps)
3. [Multilateral Marketplace — Beyond Buyers and Sellers](#3-multilateral-marketplace--beyond-buyers-and-sellers)
4. [Three-Layer Information Architecture](#4-three-layer-information-architecture)
5. [Semantic Matching Engine (Module 1)](#5-semantic-matching-engine-module-1)
6. [Trusted Intermediary Protocol (Module 2)](#6-trusted-intermediary-protocol-module-2)
7. [Multimodal Input Pipeline (Module 3)](#7-multimodal-input-pipeline-module-3)
8. [Asynchronous Brokerage Agents (Module 4)](#8-asynchronous-brokerage-agents-module-4)
9. [Memory and Context Management (Module 5)](#9-memory-and-context-management-module-5)
10. [Trust Gradation Framework (Module 6)](#10-trust-gradation-framework-module-6)
11. [Dynamic Pricing Module (Module 7)](#11-dynamic-pricing-module-module-7)
12. [Dispute Resolution Pipeline (Module 8)](#12-dispute-resolution-pipeline-module-8)
13. [User Aggregation & Cooperatives](#13-user-aggregation--cooperatives)
14. [Psychological Framing & Personalization](#14-psychological-framing--personalization)
15. [Sales & Proactive Outreach](#15-sales--proactive-outreach)
16. [Synthetic Market Bootstrapping (ClientSynth Integration)](#16-synthetic-market-bootstrapping-clientsynth-integration)
17. [Digital Twins](#17-digital-twins)
18. [Geographic & Temporal Distance Modelling](#18-geographic--temporal-distance-modelling)
19. [Regulatory & Compliance Layer](#19-regulatory--compliance-layer)
20. [Fulfillment & Settlement Integration](#20-fulfillment--settlement-integration)
21. [Framework Generalization ("Slots Architecture")](#21-framework-generalization-slots-architecture)
22. [Data Model & Schema Evolution](#22-data-model--schema-evolution)
23. [Frontend & UX Gaps](#23-frontend--ux-gaps)
24. [Infrastructure & Operations](#24-infrastructure--operations)
25. [Intervention Matrix Coverage Analysis](#25-intervention-matrix-coverage-analysis)
26. [Prioritised Implementation Phases](#26-prioritised-implementation-phases)

---

## 1. Whitepaper Module Inventory vs. Current Implementation

Chapter 32 explicitly lists the eight Cosolvent modules. Current status:

| #   | Whitepaper Module             | CosolventAI Component                                                  | Status                                                    |
| --- | ----------------------------- | ---------------------------------------------------------------------- | --------------------------------------------------------- |
| 1   | Semantic matching engine      | `search_service` (pgvector, embeddings, similarity search)             | **Partial** — functions but needs enrichment              |
| 2   | Trusted intermediary protocol | *None*                                                                 | **Missing**                                               |
| 3   | Multimodal input pipeline     | `llm_orchestration_service` (`metadata_extraction.py`, `translate.py`) | **Placeholder** — stubs return hardcoded strings          |
| 4   | Asynchronous brokerage agents | *None*                                                                 | **Missing**                                               |
| 5   | Memory and context management | `industry_context_service` (RAG + chat)                                | **Partial** — domain knowledge exists, no per-user memory |
| 6   | Trust gradation framework     | `producers.status` field + manual admin approval                       | **Minimal**                                               |
| 7   | Dynamic pricing module        | *None*                                                                 | **Missing**                                               |
| 8   | Dispute resolution pipeline   | *None*                                                                 | **Missing**                                               |

**Key finding:** Of the eight core modules, only Module 1 is partially operational. Module 3 has infrastructure but no working implementation. Modules 5 and 6 have faint echoes. Modules 2, 4, 7, and 8 are entirely absent.

---

## 2. Market Physics — Domain Model Gaps

### What the whitepaper says (Parts II–III)

The framework distinguishes **market characteristics** (descriptive dimensions: desire to exchange, arrangement of counterparties, B2B/B2C/C2C combinations, theoretical maximum size) from **market challenges** (existential: risk, trust, regulation; resistance: information density, geographic distance, temporal distance, opacity, cold start, cognitive bandwidth, fulfillment constraints).

Each market segment should be explicitly assessed against these dimensions before engineering interventions are chosen.

### Current state

There is **no explicit representation** of market physics anywhere in the codebase. The `docs/design/thin_market_framework_v1.md` document acknowledges this implicitly (it references the admin dashboard showing "Market Force scores") but no implementation exists.

The `init.sql` schema, Pydantic models, and service routes carry some implicit signals — `region`, `certifications`, `primary_crops` — but these are domain-specific (agriculture) rather than generalised market physics attributes.

### Required changes

- **Introduce a Market Physics Scorecard model.** Each marketplace instance (or vertical) should record assessments for:
  - Structural vs. transient desire to exchange
  - Counterparty arrangement (1-to-1, 1-to-many, many-to-many)
  - Participant types (B2B, B2C, C2C, C2B)
  - Theoretical maximum market size
  - Severity ratings for each challenge dimension (risk, trust, regulation, opacity, information density, geographic/temporal distance, cold start, cognitive bandwidth, fulfillment)
- **Build a diagnostic wizard or LLM-driven assessment tool** that generates an initial scorecard from a textual market description.
- **Wire the scorecard into the matching and intervention selection logic.** The system should adjust which modules it activates and how aggressively, based on which forces dominate the target market.

---

## 3. Multilateral Marketplace — Beyond Buyers and Sellers

### What the whitepaper says (Chapters 2–5, 8–13, 15–20)

A functioning marketplace requires **both buyers and sellers** with rich profiles. The whitepaper discusses importer needs, procurement requirements, budget ranges, and bidirectional matching throughout.

But the whitepaper also describes a richer ecosystem. Chapters 8–13 cover traditional market engineering roles — **brokers, market makers, clearinghouses, standards bodies, storage/logistics providers** — that AI augments but does not eliminate. Chapter 19 (Asynchronous Brokerage) and Chapter 13 (Clearinghouses) describe facilitators who enable deals rather than being counterparties to them. The real-world thin markets the whitepaper targets — cross-border agricultural trade, specialty manufacturing — routinely require customs brokers, quality inspectors, shipping agents, trade finance providers, and insurance underwriters to close a single deal.

### The architectural insight: Three participant categories

The marketplace needs to support not two but **three fundamentally different categories** of participant:

| Category                             | Role                              | How they enter                                  | Matching pattern                     |
| ------------------------------------ | --------------------------------- | ----------------------------------------------- | ------------------------------------ |
| **Principals** (Sellers)             | Offer goods/services/capabilities | Self-registration, gallery profile              | Matched *against buyer requirements* |
| **Principals** (Buyers)              | Seek goods/services/capabilities  | Self-registration, gallery profile              | Matched *against seller offerings*   |
| **Facilitators** (Service Providers) | Enable deals between principals   | Self-registration *or* deal-triggered discovery | Matched *against deal requirements*  |

Examples of facilitators in a cross-border agricultural context:

| Facilitator Type                | What they provide                                                            | When they're needed                                         |
| ------------------------------- | ---------------------------------------------------------------------------- | ----------------------------------------------------------- |
| Customs broker                  | Import/export clearance for specific origin/destination/product combinations | After buyer-seller match, during deal structuring           |
| Shipping / logistics            | Route-specific transport, cold chain, warehousing                            | After match, when fulfillment details are known             |
| Quality inspector               | Product-specific certification, grading, lab analysis                        | Before or during deal, depending on buyer requirements      |
| Trade finance provider          | Letters of credit, export financing, insurance                               | During negotiation, when deal value and risk are quantified |
| Insurance underwriter           | Cargo insurance, trade credit insurance                                      | During deal structuring                                     |
| Legal / compliance advisor      | Cross-jurisdictional regulatory guidance                                     | When regulatory complexity is high                          |
| Translation / cultural mediator | Language and cultural bridging                                               | Throughout deal lifecycle                                   |

### Current state

The system is **overwhelmingly seller/producer-centric**, and has **no concept of service providers**:
- **Database:** The `producers` table has 20+ columns specific to farm exporters. The generic `participants` table (with `type`, `email`, `data` JSONB) is a positive step toward generalization — its open `type` field could hold `'logistics_broker'` or `'inspector'` today — but it has no routes, no service logic consuming it, and no frontend.
- **Schemas:** `ProducerRegisterSchema` and `ProducerSchema` dominate the `profile_service`. `ImporterProfileSchema` exists in `llm_orchestration_service/src/config/models.py` but is only used for LLM-driven profile generation — it is never persisted.
- **Search:** The `search_service` indexes and queries producers only. `IndexRequest` expects `ai_profile`, `region`, `certifications`, `primary_crops` — all seller-side attributes. There is no concept of searching for service providers based on deal requirements.
- **Frontend:** The landing page (`HeroSection`, `ProducersSection`, `LiveOfferingsSection`) and chatbot are producer-facing.
- **No Deal entity.** There is no data model for an in-progress deal, which means there is nothing for service providers to attach to.

### Required changes

#### 3.1 — Buyer-side foundation
- **Build a buyer registration and profile flow**, either as a new service or by extending `profile_service` to handle multiple participant types using the `participants` table.
- **Extend search for bidirectional matching.** Buyers should search for sellers, sellers should search for buyers. The new `participant_embeddings` table could serve both entity types, keyed by `type`.
- **Build buyer-side frontend views:** dashboard, search, saved searches, match notifications, deal tracking.
- **Align the `/index` and `/search-producers` routes** to support both entity types, or introduce parallel routes for buyer discovery.

#### 3.2 — Service provider profiles
- **Define facilitator participant types.** The `participants` table's open `type` field supports this without schema changes. Facilitator types should be admin-configurable (via the `MarketDefinition` schema's `participant_schema` field) so that each marketplace vertical can define relevant facilitator categories.
- **Build facilitator gallery profiles.** Service providers need gallery profiles too — a customs broker's profile should show jurisdictions covered, product categories handled, certifications held, languages spoken, and client testimonials. The three-layer model (Section 4) applies: gallery for discovery, matching profile for AI-driven deal attachment.
- **Facilitator-specific matching metadata.** Unlike principals, facilitators match on **capability dimensions**: geographic coverage (origin/destination pairs), product category expertise, service turnaround time, pricing structure, capacity availability, and regulatory jurisdiction knowledge.

#### 3.3 — Deal entity and role slots
- **Introduce a Deal data model.** A deal represents an in-progress transaction between principals, with structured requirements that evolve as the deal progresses:
  - Principals involved (buyer, seller — references to `participants`)
  - Product/service being transacted
  - Route (origin country/region → destination country/region)
  - Volume, value, and timeline
  - Quality/certification requirements
  - **Role slots** — a list of facilitator roles the deal needs, each with a status:
    - `needed` — the deal requires this role but no facilitator is attached
    - `searching` — the system is actively searching for a facilitator
    - `proposed` — a facilitator has been identified and proposed to the principals
    - `confirmed` — a facilitator is attached to the deal
    - `not-needed` — this role is not required (e.g., both parties are in the same jurisdiction, so no customs broker is needed)
- **Build deal-triggered facilitator search.** When a buyer-seller match progresses to deal structuring, the system should:
  1. Analyze the deal's requirements (route, product, regulatory jurisdictions, value)
  2. Determine which facilitator roles are needed
  3. Search for facilitators whose capabilities match the deal's specific requirements
  4. Propose facilitators to the principals
- This is a **second matching pattern** — distinct from participant-to-participant matching. It matches a *deal's structured requirements* against *facilitator capability profiles*.

#### 3.4 — Facilitator engagement model
- **Facilitators don't browse the gallery the same way principals do.** Their primary interface is a **deal feed** — a stream of deals that match their capabilities, where they can express interest.
- **Principals see facilitators as part of deal assembly.** When viewing a deal, the buyer/seller sees which roles are filled and which are open, with AI-recommended facilitators for open slots.
- **Commission/fee structures** will eventually need to support facilitator compensation, but this is a later-phase concern.

#### 3.5 — Communication architecture

For participants to move from discovery to deal-making, they need **privacy-layered communication** that mirrors the three-layer information model (Section 4). Communication channels are scoped to contexts (matches, deals), not to individuals — you don't "message a user," you communicate within a shared context that both parties opted into.

| Stage                    | Trigger                  | Channel                                | What flows                                                               | Privacy model                                                                                             |
| ------------------------ | ------------------------ | -------------------------------------- | ------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------- |
| **Gallery browsing**     | User browses directory   | No direct contact                      | Public profile only                                                      | Enough to research externally, but the platform doesn't facilitate cold outreach                          |
| **Match introduction**   | AI recommends a match    | System-mediated intro                  | Match rationale + gallery profiles                                       | Both parties see *that* they were matched and *why*, but not each other's private data                    |
| **Match conversation**   | Either party opts in     | Scoped messaging channel               | Messages in the context of this specific match                           | Between the two parties + AI; neither sees the other's matching profile — only what each chooses to share |
| **Deal channel**         | Match progresses to deal | Multi-party deal space                 | Deal parameters, messages, shared documents                              | All deal participants (principals + attached facilitators) communicate within the deal scope              |
| **Selective disclosure** | A party chooses to share | Document/field elevation within a deal | A specific document or data point is shared with a specific counterparty | Granular, per-item, per-counterparty, revocable                                                           |

Key design principles for communication:
- **Context-scoped.** Every communication occurs within a match or deal. This prevents spam, provides shared context, and lets the AI participate meaningfully (suggesting talking points, flagging misalignments, bridging language barriers).
- **AI introduces, then steps back.** The matching algorithm creates introductions — not the user. Early communications are AI-mediated; as trust builds, parties communicate more directly.
- **Trust unlocks channels.** You can't skip stages. Each progression (match accepted, deal initiated, document shared) is an explicit trust action visible to both parties.
- **The platform holds the record.** Communication history supports dispute resolution, AI learning (match quality assessment, preference evolution), and regulatory compliance.

#### 3.6 — Platform scope: from matching to handoff

The platform's V1 scope is **matchmaking and introduction**, not full transaction execution. The analogy is a dating site: match → introduce → build confidence → schedule the meeting → done. What happens at the meeting is between the parties.

In thin markets, the hard problem is **finding and qualifying counterparties who wouldn't otherwise discover each other**. Once parties have been matched, introduced, and have built sufficient confidence through progressive communication, they can close the deal using existing mechanisms — lawyers, banks, logistics companies — outside the platform.

The platform lifecycle in V1:

```
Gallery Browsing → AI Match → Introduction → Conversation → Deal Assembly → Handoff Artifact → Offline
```

**The Handoff Artifact is the platform's primary deliverable.** It is the structured output document that carries the platform's value into the offline deal execution process — a package designed to be given to the downstream professionals (lawyers, banks, logistics providers, regulators) who will structure and execute the transaction.

The Handoff Artifact is assembled from information already in the system: gallery profiles, matching signals (sanitized), conversation context, shared documents, facilitator recommendations, and regulatory flags. The AI curates and structures what the parties have established through their platform interaction.

**The Handoff Artifact is a framework concept, not a trade-specific document.** Cosolvent is intended to scaffold smart market organizers across many different thin markets. In every vertical, the platform's destination is a domain-specific handoff artifact — but the *structure* is the same: principals identified, fit established, facilitators recommended, relevant context packaged.

| Thin Market Vertical            | Principals                         | Facilitators                                             | Handoff Artifact        | Downstream consumers                                 |
| ------------------------------- | ---------------------------------- | -------------------------------------------------------- | ----------------------- | ---------------------------------------------------- |
| Cross-border agricultural trade | Exporter, Importer                 | Customs broker, shipper, inspector, trade finance        | **Deal Brief**          | Bank, trade lawyer, freight forwarder                |
| Remote mental health services   | Patient, Provider                  | Support services, insurance, translation                 | **Plan of Care**        | Primary care physician, insurer, support coordinator |
| Specialty manufacturing         | Design firm, Contract manufacturer | Materials supplier, quality lab, IP counsel              | **Production Brief**    | Procurement team, quality assurance, legal           |
| Art / collectibles              | Seller, Collector                  | Appraiser, authenticator, insurer, shipper               | **Transaction Package** | Auction house, insurer, art handler                  |
| Niche real estate               | Seller, Buyer                      | Inspector, lender, title company, environmental assessor | **Deal Package**        | Lender, title company, closing attorney              |

This means the Handoff Artifact template must be **admin-configurable per marketplace deployment** — connected to the Slots Architecture (Section 21) and the `MarketDefinition` schema. Each vertical defines:
- What the artifact is called
- What sections it contains
- Which participant/deal fields map to which sections
- Which downstream consumer roles receive which sections
- What regulatory or compliance context the AI should flag

**Future expansion: in-platform execution.** Some thin markets may have simple enough transactions that the platform could eventually handle them end-to-end — a "Transaction Slot" that adds e-commerce capability to a specific deployment. But this is a vertical-specific extension, not a V1 requirement.

---

## 4. Three-Layer Information Architecture

> *This section addresses an implementation-level architectural decision not explicitly covered in the whitepaper, but essential for reconciling the whitepaper's emphasis on privacy, trusted intermediation, and searchability.*

### The Design Insight

User profile information will be extracted from unstructured submissions and formalised into a static profile for each user. However, this **gallery profile** should not play a defining role in the matching process. Effective matching needs to dig more deeply — including information that the user may wish to keep private.

This naturally produces a **three-layer information model**:

#### Layer 1: Gallery Profile (Public, Static)

Extracted from user-submitted materials and curated into a browsable, searchable representation. This is what other authenticated users see — the marketplace equivalent of a LinkedIn profile:
- Designed for **discovery** ("who's out there?"), not for deep matching
- Contains polished, user-approved information only
- Powers the searchable gallery / browsable directory
- User can review and edit what appears here before publication
- **Applies to all participant types** — sellers, buyers, and facilitators (service providers) each have gallery profiles, though the content and fields differ by type

#### Layer 2: Matching Profile (AI-Only, Deep)

The full set of information the AI uses for semantic matching — including data the user may never want publicly visible:
- Budget ranges, true capacity constraints, strategic priorities, pricing flexibility
- Derived insights from uploaded documents (financial statements, certificates, lab reports)
- Inferred preferences from interaction history (search patterns, match rejections)
- Users see match *results* but **not** the underlying data from the counterparty's matching profile that drove the match
- This is where the whitepaper's "Trusted Intermediary" concept (Module 2) operationally lives
- **For facilitators:** The matching profile includes capability details used for deal-attached matching (Section 3.3) — e.g., a customs broker's actual processing capacity, preferred deal sizes, and pricing flexibility, which are not shown in their gallery profile

#### Layer 3: Source Documents (Per-Document Privacy)

The raw materials users upload (photos, certificates, lab results, invoices, contracts). Each document carries an **editable privacy setting** that controls:
- **Who can see the document directly** (public / authenticated users / matched counterparties only / AI-only / private)
- **Whether the AI can use it for matching** (opt-in per document)
- **Whether information extracted from it appears in the gallery profile** (opt-in per document)

### Why This Matters

This three-layer separation resolves a tension the whitepaper identifies but does not provide implementation detail for:

1. **Gallery profiles enable browsing without requiring trust.** Users at the whitepaper's Stage 1 (anonymous browsing) or Stage 2 (verified profile) can discover potential counterparties without either party exposing sensitive data.

2. **Matching profiles enable deep matching without exposure.** The AI can determine that Buyer A's undisclosed budget range overlaps with Seller B's undisclosed price floor — and recommend the match — without either party knowing the other's numbers. This is the operational implementation of the whitepaper's Trusted Intermediary protocol.

3. **Per-document privacy gives users control.** A user might upload a lab analysis (AI-only, for matching quality), a farm photo (public, for the gallery), and a financial statement (private, for a later verification step) — each with different visibility rules.

### Current State

The existing codebase has the **beginnings** of this architecture but does not implement the full model:

- `producer_files` has a `privacy` field (`TEXT DEFAULT 'private'`), accepted as `"public"` or `"private"` — a binary toggle, not the multi-level system needed.
- The `asset_service` stores and retrieves files with this field, and the `profile_service` passes it through during normalisation.
- `ai_profile` is generated from user-submitted data and stored on the `producers` record — but it serves as **both** the gallery view and the matching input (via `index_service.py`'s `text_to_embed = f"AI Profile: {ai_profile_data}"`). There is no separation.
- No concept of a "matching profile" distinct from the public profile.
- No mechanism for users to control which documents feed into which layer.

### Required Changes

#### 4.1 — Separate the Gallery Profile from the Matching Profile

- **Gallery Profile:** A curated, user-approved representation stored as structured data (or generated text) and displayed in the browsable directory. The user must be able to review, edit, and approve this before it goes live.
- **Matching Profile:** A richer representation that includes gallery data *plus* private signals (confidential capacity, pricing, inferred preferences from documents and behaviour). This feeds the embedding pipeline and the LLM-driven match scoring — but is never displayed to other users.
- The `ai_profile` / `ai_profile_draft` pattern on the current `producers` table is a reasonable starting point for the gallery (draft → approved workflow). The matching profile needs a separate data path.

#### 4.2 — Implement Multi-Level Document Privacy

- Expand the `privacy` field from a binary string to a structured setting with at least these levels:
  - `public` — visible to all authenticated users, extractable for gallery
  - `gallery` — visible on the user's gallery profile card, but not in search results
  - `match-only` — visible only to confirmed match counterparties
  - `ai-only` — visible only to the AI matching engine, never shown to any user
  - `private` — stored but not used for any purpose until the user changes the setting
- Each document should also carry a flag indicating whether the AI may use it for **matching input** (separate from visibility — a user might want a document AI-readable for matching but not visible even to matched counterparties).
- Privacy settings must be **editable after upload** through the user dashboard.

#### 4.3 — Build Extraction-to-Layer Routing

- When multimodal input (Module 3) extracts structured information from an uploaded document, the extraction pipeline should route the extracted data to the appropriate layer based on the document's privacy setting:
  - `public` / `gallery` documents → extracted information feeds the **gallery profile**
  - `ai-only` / `match-only` documents → extracted information feeds the **matching profile** only
  - `private` documents → nothing is extracted until privacy is changed
- This routing logic sits between the multimodal input pipeline and the profile storage, and must respect changes when a user updates a document's privacy setting.

#### 4.4 — Rebuild the Embedding Pipeline for Dual Input

- Currently, `index_service.py` generates a **single embedding** from the `ai_profile` text. Under the new architecture:
  - The **gallery search** ("browse participants") might use a lighter embedding derived from gallery profile text only.
  - The **matching search** ("find me a match") should use a richer embedding that incorporates both gallery and matching-profile data — including signals from `ai-only` documents.
  - The `participant_embeddings` table's JSONB `metadata` field is well-positioned to carry privacy-aware metadata filters.

---

## 5. Semantic Matching Engine (Module 1)

### What the whitepaper says (Chapters 15–16)

AI should "preserve heterogeneity while enabling discovery" — the central thesis. Semantic matching via vector embeddings replaces forced standardization. Generative preference elicitation (conversational discovery) replaces filter forms. Match results should include **contextual explanations** ("why this match").

### Current state — what works

- `search_service` uses **pgvector** for cosine/L2 similarity — a strong foundation.
- `embedding_service` calls `llm_orchestration_service` for vector generation.
- `QueryRequest` accepts free-text queries.
- `vector_service.query()` supports metadata filtering (region, certifications, primary crops).

### Current state — what's missing

- Embeddings are generated from `ai_profile` text only — not multi-signal.
- No separation between **gallery search** (browsing public profiles) and **matching search** (deep AI-driven matching using private signals) — see Section 4.
- No **generative preference elicitation** — the chatbot is general Q&A, not a structured matching assistant.
- No **match rationale** — `ProducerSimilarity` returns `producer_id` + `score` only.
- No **multi-vector matching** (separate embeddings for different profile facets).
- No **personalized translation** of results (the whitepaper's "which 3–5 specs matter to this buyer").

### Required changes

- **Implement three search modes** aligned with the three-layer architecture (Section 4) and the multilateral model (Section 3):
  - **Gallery search** — lightweight semantic search over public gallery profiles, for browsing and discovery. Users can filter and explore without triggering confidential matching. Applies to all participant types.
  - **Participant-to-participant match search** — deep AI-driven matching over matching profiles (including private signals), with LLM-generated rationale. Matches buyers against sellers and vice versa. This is the "real" Module 1 from the whitepaper.
  - **Deal-to-facilitator match search** — given a deal's structured requirements (route, product, regulatory jurisdictions, volume, timeline), search for service providers whose capability profiles match. This powers the deal assembly process described in Section 3.3.
- **Enrich embedding input.** The text sent to the embedding model should blend the AI profile with structured metadata in a template, e.g.: `"Products: {primary_crops}. Region: {region}. Certifications: {certifications}. Experience: {export_experience}. Profile: {ai_profile}"`. This preserves heterogeneity rather than discarding it.
- **Build generative preference elicitation.** Extend the chatbot (or build a dedicated conversation flow) that progressively asks the buyer clarifying questions, constructs a detailed requirement representation, and runs semantic search against it. This replaces the current free-text `query` field with a conversational discovery process.
- **Add match rationale generation.** After search returns results, pass each (query, candidate_profile) pair through the LLM with a "matching rationale prompt" (as described in `docs/design/thin_market_framework_v1.md`) to generate a human-readable explanation. The rationale must respect privacy boundaries — it can say "strong quality alignment" without revealing the specific lab values that drove the conclusion.
- **Consider multi-vector representations.** Separate embeddings for product quality, logistics capability, and certification alignment would allow composite scoring with adjustable weights. This is especially useful for facilitator matching, where capability dimensions are distinct from principal profile dimensions.

---

## 6. Trusted Intermediary Protocol (Module 2)

### What the whitepaper says (Chapters 6, 15, 20)

This is identified as one of the **three core AI capabilities**. AI learns confidential information from both parties and facilitates matches without mutual disclosure. This addresses strategic information withholding — the problem where "deals die not because they would not work, but because neither party will share enough to determine if they would work."

The whitepaper describes a specific flow:  
1. Buyer shares true budget, timeline, and priorities under confidentiality  
2. Seller shares actual capacity, past results, and pricing flexibility under confidentiality  
3. AI determines fit and facilitates introductions only when appropriate  

### Relationship to the Three-Layer Architecture (Section 4)

The Trusted Intermediary protocol is **operationally implemented** through the three-layer information architecture. The matching profile (Layer 2) *is* the confidential data vault — information the AI uses for matching but never exposes to counterparties. The per-document privacy controls (Layer 3) determine what data flows into this vault.

This means the Trusted Intermediary is not a separate, isolated module — it emerges from the interaction between the privacy-aware document system, the matching profile, and the LLM-driven matching pipeline.

### Current state

**Entirely absent.** All profile data is stored in a single `producers` table accessible to admins. There is no concept of buyer-submitted private requirements, no confidentiality envelope, and no AI intermediary operating on data that neither side can see. The `producer_files.privacy` field exists but is not connected to any extraction or matching logic.

### Required changes

- **Implement the matching profile as the confidential vault.** The Layer 2 matching profile (Section 4) serves as the practical implementation of the vault. Both buyers and sellers submit sensitive information (budget ranges, true capacity constraints, strategic priorities, acceptable price floors/ceilings) — documents with `ai-only` or `match-only` privacy flow into the matching profile but are never exposed in gallery views, search results, or admin panels.
- **Build a confidential matching pipeline.** The LLM-driven matching step reads from both gallery profiles and matching profiles, evaluates fit, and produces a recommendation that reveals only *that* a match exists — not the underlying sensitive data. The match rationale must be carefully worded to avoid leaking private signals.
- **Implement structured disclosure gates.** After a match is suggested, both parties opt in to progressively share more information. A user might elevate a document from `ai-only` to `match-only` (visible to the specific counterparty), or from `match-only` to `public`. This aligns with the trust gradation model (Section 10).
- **Consider MCP integration** for the vault — the design docs mention MCP slots, and the confidential vault could be implemented as a pluggable resource.

---

## 7. Multimodal Input Pipeline (Module 3)

### What the whitepaper says (Chapters 15, 21)

This is **Core Capability 3**. AI should accept information in any natural form — voice, photos, casual text, WhatsApp messages, handwritten invoices — and translate it into structured marketplace data. The Ethiopian coffee farmer and Indian turmeric examples are central Case Studies.

### Relationship to the Three-Layer Architecture (Section 4)

The multimodal input pipeline is the primary **feeder** of the three-layer model. When a user uploads a document (photo, voice memo, certificate, invoice), the pipeline:
1. Extracts structured information from the raw content
2. Checks the document's **privacy setting** to determine routing
3. Routes extracted data to the gallery profile, matching profile, or both — based on the privacy rules defined in Section 4.3

This makes per-document privacy controls an essential element of the input pipeline, not an afterthought.

### Current state

The infrastructure exists but is non-functional:
- `metadata_extraction.py` has an `image_to_text()` function that returns `"[Placeholder: Textual description...]"`.
- `speech_to_text()` similarly returns a hardcoded placeholder string.
- `extract_textual_metadata_from_file()` has a real VLM integration path (reads config for `vlm_provider`, handles image MIME types) but falls back to placeholder strings.
- `translate.py` has a working LLM-based translation service.
- The frontend **requires structured form input** for producer registration (`ProducerRegisterSchema.as_form()`).
- There is **no privacy-aware routing** — extracted data goes to a single `ai_profile` field regardless of the source document's privacy setting.

### Required changes

- **Implement real VLM integration.** Replace the `image_to_text` placeholder with a working call to a vision-language model (the code already has the wiring for `vlm_provider` config — it just needs a real provider configured and the placeholder removed).
- **Implement real STT integration.** Replace the `speech_to_text` placeholder with an actual speech-to-text model (Whisper via OpenRouter or a local model). This should support multiple languages per the whitepaper's emphasis on Amharic, Hindi, and other developing-market languages.
- **Build a "natural language listing creation" flow.** A user should be able to describe their product conversationally (typed or spoken), and the system should auto-generate a structured listing. The existing `profile_generation.py` pattern (LLM generates structured JSON from text) should be extended.
- **Implement privacy-aware extraction routing.** When extracting structured data from an uploaded document, check the document's privacy setting and route the extracted information to the correct profile layer (gallery, matching, or both). If a user later changes a document's privacy setting, re-route the extracted data accordingly.
- **Plan for WhatsApp/SMS/USSD interfaces.** The whitepaper explicitly calls for mobile-first, low-bandwidth operation. This requires an integration layer (Chapter 30's "Interface Layer") beyond the current Next.js frontend.

---

## 8. Asynchronous Brokerage Agents (Module 4)

### What the whitepaper says (Chapter 19)

AI acts as an "always-on negotiator" representing each party even when offline. This addresses temporal distance (a dedicated force in the market physics model). The AI maintains conversation state across sessions and time zones, answers detailed questions, negotiates within pre-set boundaries, and escalates to humans when needed.

The Canada-Asia canola crush example (Chapter 19) is the reference Case Study.

### Current state

**Missing.** The chatbot is a stateless Q&A interface. The `industry_context_service/src/services/chatAgent.ts` and `chatService.ts` are general RAG chat services — not autonomous agents with delegated authority.

The `docs/design/thin_market_framework_v1.md` does reference an **Agent Slot** with broker personas and negotiation rules — this is a good design starting point but has no implementation.

### Required changes

- **Introduce a "User Agent" entity and configuration model.** Each participant should be able to configure an AI agent with:
  - Pre-approved negotiation parameters (price ranges, minimum order sizes, delivery windows)
  - Authority levels (autonomous agreement vs. human approval required)
  - Persona and communication style guidelines
  - Access to tools defined in the Agent Slot (search, schedule meeting, send quote)
- **Build an asynchronous conversation engine** that can carry on multi-turn conversations across days, maintain state in the database, and escalate appropriately.
- **Build a "deal progression" workflow** tracking conversations from initial inquiry → qualification → negotiation → deal structuring → human approval → settlement.
- **Add a notification system** (email, SMS, push) so that when an agent reaches a decision boundary or needs human input, the owner is promptly alerted.

---

## 9. Memory and Context Management (Module 5)

### What the whitepaper says (Chapters 14, 17)

This is an explicitly named core capability. AI should maintain **institutional memory** — remembering the nuance of why a deal failed, tracking evolving preferences, recognising patterns across interactions, moving from "search" to "anticipation." Memory persists across participant turnover, creating institutional resilience that thin markets have historically lacked.

Three specific sub-capabilities:
1. **Contextual persistence** — why was a previous match rejected?
2. **Evidence-based trust** — verified performance "dossiers" for Trust-as-a-Service
3. **Synthesis of intent** — detecting that a user's queries are converging and proactively alerting them

### Current state

- The `industry_context_service` provides **domain knowledge memory** — ingested documents are embedded and used for RAG chat. This is the closest existing component.
- The `system_prompts` table and `prompt_registry` concept (from design docs) could store evolving context.
- However, there is **no per-user interaction memory.** No search history, no match rejection tracking, no conversation logs tied to users, no preference evolution analysis.

### Required changes

- **Add a user interaction log.** Store every search query, match view, match rejection (with optional reason), and conversation turn, linked to the authenticated user.
- **Build preference evolution analysis.** Periodically (or on-demand) analyze a user's interaction history to identify emerging patterns and converging requirements using the LLM.
- **Enable anticipatory matching.** When new listings appear that match an inferred (not explicitly stated) evolving need, proactively notify the user — the procurement manager sensor search example from Chapter 17.
- **Store deal outcome data.** For completed (or failed) transactions, record what happened and why. Use this to refine future matching and to build the "evidence-based trust dossiers."
- **Ensure memory persists across participant turnover.** When a team member who managed a relationship leaves, their accumulated interaction knowledge should remain in the system.

---

## 10. Trust Gradation Framework (Module 6)

### What the whitepaper says (Chapters 6, 28–29)

Trust operates on a **seven-stage gradient** (browsing → profile creation → sharing sensitive data → initiating contact → negotiating → committing funds → ongoing relationship). The platform must provide appropriate trust mechanisms at each stage.

Four types of AI-enabled trust: **profile verification**, **reputation inference**, **risk assessment**, and **transparent matching**.

Three levels of platform trust: **platform trust** (is the algorithm fair?), **counterparty trust** (is this entity reliable?), **transaction trust** (will the deal settle?).

### Current state

Minimal:
- A simple `status` field on the `producers` record (e.g., "approved") — the **only trust signal** in the system.
- The `admin_service` presumably approves/rejects producers manually.
- No verification pipeline, no reputation tracking, no risk scoring, no progressive disclosure mechanism.

### Required changes

- **Implement a verification pipeline.** When a participant registers:
  - Auto-analyze uploaded documents for consistency (does the certification doc match claimed certifications?)
  - Cross-reference with external data where possible
  - Assign a verification confidence score
- **Build a reputation system.** Track transaction outcomes, response times, dispute rates, and counterparty ratings. Aggregate into a "trust score" with appropriate privacy controls.
- **Implement the progressive trust model** (the whitepaper's six-stage gradient), integrated with the per-document privacy controls from Section 4:
  1. Anonymous browsing → only public gallery profiles visible
  2. Verified profile → identity and basic capability confirmed; AI begins using `ai-only` documents for matching
  3. Guided introduction → AI-mediated initial contact; gallery profile shared, nothing from matching profile
  4. Structured information exchange → progressive disclosure; user can selectively elevate specific documents from `ai-only` to `match-only` for this counterparty
  5. Protected transaction → escrow, insurance, dispute resolution in place; broader document access as warranted
  6. Post-transaction evaluation → bidirectional ratings that build long-term reputation
- **Add transparent matching.** Surface the AI's reasoning for each match — which factors drove the quality score, what risks were identified — while respecting privacy boundaries (no leaking of `ai-only` data in rationale text).
- **Privacy as a prerequisite.** The whitepaper emphasises (Chapter 29): "Privacy is not a feature — it is a prerequisite for market participation in thin markets." The three-layer architecture (Section 4) provides the structural foundation for this principle; the trust gradient operationalises it.

---

## 11. Dynamic Pricing Module (Module 7)

### What the whitepaper says (Chapter 18)

AI should calculate **"fair theoretical value"** in real time: "Based on 2,300 comparable transactions in the last 12 months, adjusting for protein content, moisture, location, shipping costs, and current futures prices, fair value for this lot is $CAD 412–428/tonne."

This addresses the "market for lemons" problem by giving both parties a credible, neutral anchor.

### Current state

**Entirely absent.** No price fields exist in any schema. No transaction history is stored. No valuation logic is present anywhere.

### Required changes

- **Add pricing fields to the data model.** Listings need asking prices, accepted price ranges, and pricing metadata (currency, unit, conditions).
- **Create a transaction history model.** Record completed deals with actual prices, dates, quality attributes, and participant ratings.
- **Build a fair-value estimation service** that:
  - Ingests comparable transaction data (initially seeded, later populated organically)
  - Adjusts for quality attributes, location, seasonality, and volume
  - Produces a confidence-banded price estimate
- **Integrate pricing into the matching flow.** When a match is suggested, include a fair-value estimate so both parties have a credible anchor.
- **Initially:** This module can be simple — even a basic "here are the 10 most recent comparable transactions" would add significant value in thin markets where price discovery is the core problem.

---

## 12. Dispute Resolution Pipeline (Module 8)

### What the whitepaper says (Chapter 24)

Disputes in thin markets are disproportionately damaging — one bad experience can permanently discourage a participant. AI should provide:
- **Automated triage** — classify by severity and route appropriately
- **AI-assisted evaluation** — analyze evidence using documentation and historical benchmarks
- **Predictive dispute prevention** — flag high-risk transactions before they occur

### Current state

**No dispute resolution system** of any kind.

### Required changes

- **Add a disputes data model and service.** Allow either party to file a claim, attach evidence, and describe the issue.
- **Build an AI triage system** that classifies disputes, suggests resolutions for minor issues (credits, adjustments), and escalates complex cases to human mediators with full context prepared.
- **Implement predictive risk scoring** on in-progress deals — flag transactions with patterns historically associated with disputes (communication anomalies, vague contract terms, unusual volume/price combinations).

---

## 13. User Aggregation & Cooperatives

### What the whitepaper says (Chapters 5, 22)

Many potential participants are individually too small to be commercially relevant. AI facilitates combining them into collective units — quality-sorted batching, demand aggregation, logistics coordination, and fair revenue allocation. The Ethiopian Cold Chain Cooperative Case Study (Chapter 22) is the reference.

### Why this is architecturally significant

Aggregation is not a feature — it is a fundamental response to the structural reality of most thin markets. In developing-country agriculture, most growers are smallholders. They don't grow enough to serve a buyer in a nearby city, let alone overseas. A single Kenyan coffee farmer may produce 500kg; a European specialty roaster wants 20 tons. A Saskatchewan wheat farmer may cultivate 10,000 acres, but a major Indonesian brewery may want 100,000 tons annually.

The same dynamic applies beyond agriculture. Any domain where aggregate demand is large but individual production is comparatively small faces this problem: artisan manufacturing, distributed renewable energy, rural healthcare staffing, creative services.

The practical real-world answer is collective entities — cooperatives, marketing companies, producer associations, aggregation agents. The platform must support these as first-class participants, not as a bolted-on afterthought.

### The Collective Participant concept

A **Collective** is a participant that *contains* other participants. Externally, a buyer interacts with the collective the same way they'd interact with a large individual exporter. Internally, the collective has member management, contribution tracking, and order allocation.

A collective has:
- Its own **gallery profile** — brand, description, collective certifications, geographic coverage
- Its own **matching profile** — derived from aggregated member data (total volume, quality distribution, delivery windows, production capacity)
- Its own **listings** — aggregated offerings that no single member could fulfill alone
- A **membership roster** — with roles (manager, member, field agent)
- **Supply schedules** — not static totals but time-phased availability derived from member commitments

The key design principle: **a collective is a participant in the marketplace that happens to have internal structure.** It matches against buyers, enters deals, generates Handoff Artifacts — all using the existing framework machinery. The aggregation layer adds internal member management on top.

### Member experience (accessibility-first)

A smallholder contributing 500kg of coffee to a cooperative does not need — and in many cases cannot use — the full marketplace interface. The member experience must be designed for users who may be:

- On feature phones, not smartphones
- Communicating via SMS or WhatsApp, not web browsers
- Working through a field agent who enters data on their behalf
- Minimally literate or literate in a language the UI doesn't yet support

What a member needs:

| Capability                    | Description                                                  | Interface                                           |
| ----------------------------- | ------------------------------------------------------------ | --------------------------------------------------- |
| **Data submission**           | "I have 500kg Grade A, available March"                      | SMS, WhatsApp, field agent entry                    |
| **Contribution visibility**   | See that their contribution is part of a larger offering     | SMS confirmation, simple status page                |
| **Payout transparency**       | When the group's listing sells, know their share             | SMS notification, simple ledger view                |
| **No marketplace navigation** | Members don't browse galleries, don't match, don't negotiate | The group manager handles all external interactions |

This connects directly to B1.6 (WhatsApp/SMS/USSD interface layer). For cooperatives, low-bandwidth input channels aren't nice-to-have — they're the primary interface for most members.

### Aggregation logic (framework mechanism, vertical rules)

Aggregation means different things in different markets. The framework provides the aggregation *mechanism*; the vertical defines the aggregation *rules*.

| Vertical                   | What's aggregated                              | Aggregation challenge                                                             |
| -------------------------- | ---------------------------------------------- | --------------------------------------------------------------------------------- |
| Agricultural trade (grain) | Volume, quality grades, delivery windows       | Quality sorting — buyer wants Grade A only, co-op has mixed grades across members |
| Specialty coffee           | Micro-lot characteristics, cupping scores      | Preserving lot identity vs. blending for commercial volume                        |
| Artisan crafts             | Production capacity, style categories          | Maintaining individual artisan identity within collective brand                   |
| Remote healthcare          | Clinician availability, specialties, languages | Scheduling and coverage across time zones and locations                           |
| Distributed manufacturing  | Machine capabilities, capacity, lead times     | Reliability and quality consistency across shops                                  |

**Framework responsibility:**
- Group entity data model with membership and roles
- Aggregated profile computation engine (configurable — which fields sum, which average, which concatenate)
- Aggregated listing model with supply schedules
- Member data submission pipeline (low-bandwidth channels)
- Order allocation framework (when a deal closes, a configurable rule distributes among members)
- Contribution and allocation tracking

**Vertical responsibility:**
- Aggregation rules for domain-specific fields (how quality grades combine, what "Grade A" means)
- Member data schemas (what a smallholder submits vs. what a large producer submits)
- Revenue/payout distribution logic (per-unit, quality-weighted, proportional, etc.)
- Cooperative governance rules (membership criteria, voting, dispute resolution)

### Temporal aggregation

Aggregation also addresses **temporal distance** — one of the core thin market friction types. A single producer has one harvest. A cooperative with members across microclimates, planting schedules, or regions can offer more continuous supply.

The aggregated listing needs to express supply schedules, not just totals:

> "5 tons Grade A in March, 8 tons in April, 12 tons Grade A + 4 tons Grade B in May"

This is different from a static listing. It's a **supply plan** that the group manager maintains by aggregating member commitments over time. For a buyer with continuous demand (an Indonesian brewery that needs malting barley year-round), matching against a supply plan is fundamentally more useful than matching against a static volume number.

The framework provides time-phased listing fields and schedule-aware matching. The vertical defines the time granularity (weekly, monthly, seasonal) and how member commitments roll up.

### Current state

**No aggregation concept.** Each producer is independent. No cooperative entity, no collective listings, no aggregation logic.

### Required changes — three implementation tiers

**Tier 1 — Group as marketplace participant** (framework, A2 phase)

The minimum viable collective: a group entity that matches against buyers as a single participant.

- Add a `group` participant type that contains a membership list and designates a manager
- The group manager creates and maintains the collective gallery and matching profiles manually
- The group appears in search and matching like any other participant
- A group can enter deals and receive Handoff Artifacts
- Members are listed internally but don't require platform accounts

**Tier 2 — Member-aware aggregation** (framework + vertical, A2+ phase)

Members become active contributors. Profiles aggregate automatically.

- Members can submit data through low-bandwidth channels (SMS, WhatsApp, field agent — connects to B1.6)
- The group's matching profile and listings are computed from aggregated member data
- Supply schedules are derived from member commitment timelines
- Order allocation tracking — when a deal closes, the system records per-member contribution and allocation
- Contribution visibility for members (simple status messages, not full UI)

**Tier 3 — Cooperative management platform** (vertical-specific)

Full cooperative management — this is the vertical's responsibility, built on the framework's group entity.

- Revenue distribution and payout logic per vertical rules
- Cooperative governance (membership criteria, quality standards, compliance)
- Seasonal planning and commitment management
- Certification management at group level
- Integration with logistics for aggregate shipment coordination
- Reporting for group managers and external auditors

---

## 14. Psychological Framing & Personalization

### What the whitepaper says (Chapter 23)

AI performs psychographic profiling of users and dynamically frames messages:
- Risk-averse users → safety, guarantees, social proof
- Opportunistic users → upside, scarcity, competitive advantage
- Analytical users → data, comparisons, logical justification

### Current state

**No personalization.** All users see the same content, messaging, and interface.

### Required changes

- **Add behavioural analytics tracking** for interaction patterns.
- **Build a psychographic classification module** (primarily a prompt-engineering task on top of the existing LLM service).
- **Implement dynamic message framing** in the chatbot, match notifications, and listing displays.

---

## 15. Sales & Proactive Outreach

### What the whitepaper says (Chapter 25)

AI-driven sales: intelligent outreach, 24/7 qualification, objection handling from the full knowledge base, and proactive discovery (monitoring business signals and reaching out when relevant inventory appears).

### Current state

**No outreach capability.** The system is entirely passive — users must initiate all interactions.

### Required changes

- **Build a proactive matching notification system.** When new listings or participants appear that match an existing user's known needs, alert them.
- **Integrate outreach generation.** Use the LLM to craft personalised outreach messages explaining why a match is relevant.
- **Consider external signal monitoring** (RSS, news APIs, procurement notice feeds) to identify potential participants before they discover the platform.

---

## 16. Synthetic Market Bootstrapping (ClientSynth Integration)

### What the whitepaper says (Chapters 26, 33)

ClientSynth generates populations of **plausible synthetic users** — demographically plausible, behaviourally realistic, economically coherent, and culturally appropriate. These serve three purposes:
1. Testing matching algorithms before real deployment
2. Demonstrating market viability to investors
3. Providing "ghost liquidity" that converts to real transactions as real users join

### Current state

**No ClientSynth integration.** The current `CosolventAI` codebase is a separate repository from `ClientSynthAI`.

### Required changes

- **Define an API contract between Cosolvent and ClientSynth.** ClientSynth should be able to generate synthetic participants that conform to whatever participant schema the current Cosolvent instance defines.
- **Build a "synthetic mode" flag** that clearly distinguishes synthetic participants from real ones in the database and UI.
- **Implement synthetic scenario execution:** given a ClientSynth population, run matching, pricing, and agent interactions to produce testable market dynamics.
- **Plan the transition path** from synthetic-to-real: as real users join, synthetic profiles should gracefully phase out or be clearly labelled.

---

## 17. Digital Twins

### What the whitepaper says (Chapter 34)

A Digital Twin combines Cosolvent infrastructure + ClientSynth population + calibrated market physics parameters to create a **complete, functioning simulation** of a thin market. Three uses: testing system design, validating market physics hypotheses, and demonstrating viability to sponsors.

The feedback loop: Build → Test → Deploy → Collect real data → Recalibrate → Iterate.

### Current state

**No Digital Twin capability.**

### Required changes

- **This is a Phase 5+ initiative.** It depends on the Market Physics Scorecard (Section 2), ClientSynth integration (Section 15), and at least partial implementation of the eight core modules.
- **When the time comes:** Build a simulation harness that can run a Cosolvent instance against a ClientSynth population with configurable market physics parameters and produce quantitative metrics (matching effectiveness, price accuracy, trust progression, deal completion rates).

---

## 18. Geographic & Temporal Distance Modelling

### What the whitepaper says (Chapters 7)

Physical distance and temporal distance are **distinct forces** requiring different engineering solutions. The whitepaper emphasises that conflating them leads to "misdiagnosis and misapplied engineering." Physical distance tables have six categories (hyper-local through virtual). Temporal distance operates at three scales (hours-days, weeks-months, months-years).

### Current state

- `region` is a text field on profiles and embeddings — no coordinates, no distance calculations.
- **No temporal awareness.** No availability windows, harvest seasonality, time-zone handling, or delivery windows.

### Required changes

- **Add geolocation data** (lat/long) for participants. Use for logistics cost estimation and distance filtering.
- **Add temporal availability models.** Listings need production/availability windows ("harvest: Sep–Oct", "available for shipment: Nov–Mar"). Buyers specify desired delivery windows.
- **Build temporal matching.** The matching engine should consider whether supply and demand windows overlap, and flag temporal gaps that need storage, forward contracting, or other engineering.
- **Add time-zone-aware communication** to the asynchronous brokerage agents (Section 7).
- **Model economic shipping radii** (from Chapter 7's table) as configurable parameters per product category.

---

## 19. Regulatory & Compliance Layer

### What the whitepaper says (Chapters 6–7)

Regulatory friction can fragment markets so severely that they cannot form. The Standards War between Middle Powers' "benign standards" and US tech titans' "powerplay standards" is a strategic theme. The whitepaper calls for adapting to different jurisdictions, providing compliance tooling, and understanding which regulatory regimes apply.

### Current state

The system has a `country` field on the producer record and nothing else. No compliance checks, no standards verification, no cross-border regulatory guidance.

### Required changes

- **Add regulatory context as a configurable data source.** For each market vertical and jurisdiction pair, maintain relevant regulations, standards requirements, and compliance procedures (this could live in the `industry_context_service` as a structured knowledge domain).
- **Integrate regulatory flags into matching.** When matching participants across jurisdictions, automatically flag relevant requirements.
- **Build a compliance checklist generator** that produces a structured list of regulatory steps for a specific cross-border match.

---

## 20. Fulfillment & Settlement Integration

### What the whitepaper says (Chapters 7, 13)

Fulfillment constraints determine whether goods can actually be delivered after matching. Economic shipping radii, cold chain requirements, and settlement mechanisms (escrow, letters of credit) are fundamental market physics.

### Current state

**No fulfillment or settlement integration.** The system ends at "here is a matched profile ID."

### Required changes

- **Add logistics estimation** — given a matched pair, estimate shipping costs and logistics complexity.
- **Model economic shipping radii** as configurable parameters to enable hard geographic filters.
- **Integrate payment/settlement primitives or interfaces** — at minimum, generate letter-of-credit outlines or integrate with escrow APIs.
- **Cold chain awareness** for applicable product categories (flagged in the Market Physics Scorecard).

---

## 21. Framework Generalization ("Slots Architecture")

### What team design docs say (`thin_market_framework_v1.md`, `admin_interface.md`)

The team has already identified the need to move from a **single-instance agricultural marketplace** to a **configurable framework** with five "Slots":
- **Intelligence Slot** — pluggable LLM providers/models, with the ability to assign **different models to different tasks**. A single "primary LLM" is insufficient: real-world deployments will need specialised models for language processing (e.g., an Amharic-tuned model from HuggingFace for Ethiopian participants), vision (VLM for document images), embeddings, and general reasoning — all running simultaneously and routed by task.
- **Context Slot** — pluggable data ingestion sources for *participant-supplied* documents (file upload, Google Drive via MCP, Notion). These are documents that participants provide about themselves (certificates, product specs, compliance documents).
- **Knowledge Slot** — a RAG-powered reference library of *sponsor-curated* domain knowledge. Unlike the Context Slot (participant documents), the Knowledge Slot holds authoritative reference material that the marketplace sponsor progressively builds: industry regulations, trade corridor guides, draft contracts from standards bodies, compliance checklists, quality standards, and procedural how-tos. The framework provides the ingestion, embedding, retrieval, and chat pipeline; the vertical deployment provides the documents and domain-specific chat prompts. Example: an Asian grain buyer should be able to ask "what do I have to do to buy high quality malting barley from western Canada and get it delivered by container to my mill in Davao City, Philippines?" — and get an authoritative, sourced answer.
- **Search Slot** — configurable embedding models and matching prompts
- **Agent Slot** — configurable broker personas and negotiation rules

The design calls for **prompt-driven logic** (extraction, matching, and negotiation move from code to admin-managed prompts) and **dynamic profiling** (admin-defined fields replace hardcoded `Producer` schemas).

### Current state

- The `llm_orchestration_service` already has a **configuration-driven architecture** (`AppConfig`, `ServiceConfig`, `ProviderConfig`, `ClientConfig`) backed by a database table (`app_config`). This is a strong foundation for the Intelligence Slot. Each named service (e.g., `translate`, `metadata_extraction`, `profile_generation`) already points to a specific provider, so the per-service routing pattern exists.
- The `industry_context_service` and `documents` table exist as a foundation for the Knowledge Slot. The `chatbot_service` provides the conversation interface. Together these form the infrastructure side of domain Q&A, though neither is yet connected to a curated reference library with proper RAG retrieval.
- The `system_prompts` table exists but is underutilised.
- The `participants` and `participant_embeddings` tables (new in the current schema) represent a start toward dynamic profiling.
- The design docs describe MCP integration for extensibility.

### Where it falls short vs. the whitepaper

The whitepaper (Chapter 32) describes Cosolvent as a **framework for building marketplaces**, not a single marketplace. Currently:
- The producer-specific code (`ProducerRegisterSchema`, `profile_service` routes, search routes) is hardcoded and coupled to agricultural domain fields.
- There is no admin UI for defining participant types, profile fields, or matching prompts.
- No MCP client is implemented.
- **The Intelligence Slot supports only one client type** (`ClientName` enum has only `OPENROUTER`). There is no way to register a HuggingFace Inference Endpoint, a local Ollama instance, or a direct OpenAI connection as an alternative provider.
- **No task-level or prompt-level model routing.** Each service maps to one provider, but there's no mechanism for routing *within* a service based on task context (e.g., language detected, document type, participant region). If the `translate` service needs GPT-5 for English→French but a specialised HuggingFace model for Amharic→English, there's no way to express that.
- **No prompt-to-model binding.** Prompts in `system_prompts` don't carry a preferred model. An admin who writes a carefully tuned Amharic extraction prompt can't bind it to the model it was tuned for.
- **No fallback chains.** If a specialised model is unavailable, there's no mechanism to fall back to a general-purpose model.
- **No Knowledge Slot separation.** The `industry_context_service` stores documents and the `chatbot_service` can answer questions, but there is no architectural distinction between participant-supplied documents (Context Slot) and sponsor-curated reference material (Knowledge Slot). The sponsor's domain knowledge library — trade regulations, contract templates, quality standards, procedural guides — is not modelled as a separate, progressively-built resource. There is no document curation workflow, no categorisation by topic or trade corridor, and no RAG pipeline that retrieves from the reference library to answer domain questions.

### Required changes

- **Implement the Admin UI** (as described in `admin_interface.md`): Intelligence configuration page, Market Definition page (dynamic field builder), Prompt Studio, MCP Slots settings.
- **Migrate from hardcoded producer schemas to dynamic participant schemas.** The `participants` table + JSONB `data` column is the right approach; the `profile_service` routes need to be adapted to use it.
- **Build a prompt registry service.** All system prompts (extraction, matching, brokerage, rationale generation) should be stored in the `system_prompts` table and editable through the admin UI.
- **Implement an MCP client** so the backend can connect to external data sources and tools as configured by the admin.
- **Extend the Intelligence Slot to support multi-model routing:**
  - **Multiple client types.** Expand `ClientName` beyond `OPENROUTER` to support HuggingFace Inference Endpoints, Ollama (local models), direct OpenAI/Anthropic connections, and custom REST endpoints. Each client type implements the `LLMClient` abstract interface.
  - **Task-level routing.** Allow each service to define routing rules that select a provider based on context — such as detected language, document type, participant region, or task complexity. Example: the `translate` service routes Amharic text to a specialised HuggingFace model while defaulting to GPT-5 for other languages.
  - **Prompt-to-model binding.** Each entry in `system_prompts` can optionally specify a `preferred_provider` and `preferred_model`, ensuring that prompts tuned for a specific model always run on that model.
  - **Fallback chains.** Define ordered fallback lists per service: if the primary model is unavailable or returns an error, try the next model in the chain. This is essential for deployments relying on specialised models that may have lower availability.
  - **Admin UI for model management.** The Intelligence configuration page should show all registered providers, their capabilities (text, vision, STT, embedding), assigned tasks, and health status. The admin should be able to add, test, and assign models without touching code.
- **Build the Knowledge Slot:**
  - **Separate reference documents from participant documents.** Create a `reference_library` table distinct from participant-uploaded files. Reference documents are sponsor-curated, progressively built domain knowledge; participant documents follow the three-layer privacy model. The two never mix in retrieval.
  - **`reference_library` schema.** Each document chunk is stored with: `embedding VECTOR(1536)` for pgvector similarity search, `JSONB metadata` for structured tags, `source_document_id` linking back to the parent document, `chunk_text` for the actual content, and standard audit fields. The JSONB metadata carries vertical-specific tags — see below.
  - **Vertical-specific reference metadata schema.** The tag vocabulary for reference documents is defined by the vertical deployment, not hardcoded. The framework provides a `reference_metadata_schema` (analogous to `MarketDefinition` for participant fields) that the admin configures. Examples:

    | Vertical                | Metadata tags on reference documents                                                                                                                     |
    | ----------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | Agricultural trade      | `origin_region`, `destination_country`, `product_category`, `document_type` (regulation / contract / guide / standard), `trade_corridor`, `issuing_body` |
    | Remote mental health    | `jurisdiction`, `insurance_provider`, `service_type`, `clinical_area`, `license_type`, `regulatory_body`                                                 |
    | Specialty manufacturing | `material_class`, `standard_body` (ISO / ASTM / DIN), `export_control_regime`, `process_type`                                                            |

  - **Document curation workflow.** Admin can upload, tag (using the vertical's metadata schema), describe, and version reference documents. The sponsor progressively builds this library over time. Documents are chunked, embedded, and immediately available for retrieval. No physical sharding is needed — the metadata tags handle scoping.
  - **Metadata-filtered vector search (not physical sharding).** Retrieval uses metadata pre-filters *before* vector similarity ranking, in a single query. This avoids the complexity of physical partitioning while achieving the same goal: an Indonesian buyer never sees Japanese import regulations in their context window. The pattern:

    ```sql
    SELECT chunk_text, source_document, metadata
    FROM reference_library
    WHERE destination_countries && ARRAY[$user_country]
      AND product_categories && ARRAY[$user_interests]
      AND document_type = ANY($relevant_types)
    ORDER BY embedding <=> $query_embedding
    LIMIT $k;
    ```

    This is one table, one vector index, one query. Documents can carry multiple tags (a guide to Incoterms is tagged with every destination country it applies to), and cross-corridor queries work naturally.

  - **Automatic user-context scoping.** The system injects the participant's metadata (country, role, product interests, active deal corridors) as implicit retrieval filters. The user doesn't type "show me Philippines regulations" — they just ask their question, and the system scopes retrieval based on what it already knows about them. This is the same pattern as the three-layer information architecture: the system uses participant context to filter what it retrieves.
  - **Domain Q&A chat integration.** The `chatbot_service` should support a "domain knowledge" mode where it answers from the reference library, distinct from participant-to-participant messaging or deal-scoped conversation. Answers are sourced — each response cites which reference documents informed the answer.
  - **Vertical-supplied prompts.** The Knowledge Slot's chat behaviour is configured via `system_prompts`: the vertical deployment defines the persona ("You are a trade advisor specialising in Asia-Pacific grain imports"), the citation style, and the scope boundaries ("only answer from reference material; say 'I don't have this information' otherwise").

### Cross-slot architectural guardrails

The five slots will eventually need to work together — for example, a buyer's domain Q&A answer could incorporate not just reference library material but also knowledge of available sellers, relevant service providers, and active deal context. This "cross-collection intelligence" is a future capability, not a V1 requirement. However, the following three guardrails should be observed *now* to avoid architectural choices that would make cross-slot reasoning harder later:

1. **Same embedding model and dimensions across all vector stores.** The `reference_library` table and `participant_embeddings` table must use the same embedding model (configured through the Intelligence Slot's `embeddings` service). If they diverge into different models or dimensions, cross-collection similarity search becomes impossible without re-embedding.

2. **Shared metadata vocabulary.** Concepts that appear in both participant profiles and reference documents — geography (countries, regions), product categories, certification types — should use the same controlled vocabulary. Both `MarketDefinition` (which defines participant field values) and `reference_metadata_schema` (which defines document tag values) should draw from shared taxonomy lists. One dropdown source, not two.

3. **Composable retrieval interface.** The retrieval layer should return results as `{source, content, metadata, score}` tuples regardless of which table they came from. Today, each caller requests from one source (participant search queries `participant_embeddings`; domain Q&A queries `reference_library`). The interface should accept a source parameter (participants, reference_library, or both) so that future callers can request merged, cross-collection results without building a new pipeline.

These three constraints cost nearly nothing to implement — they are design decisions, not features — but they preserve the path to cross-slot intelligence when the time comes.

### UI customization layers

As a framework for building marketplaces, Cosolvent must support vertical-specific UI without requiring each vertical to fork the frontend. Three layers of customization are needed, with decreasing framework responsibility:

**1. Terminology (framework mechanism, vertical content)**

Every user-facing label should read from `MarketDefinition.ui_labels` — a JSON map that translates framework concepts to vertical-specific names. This is the highest-leverage customization because incorrect terminology (a mental health marketplace labelled "Producer" and "Deal Brief") immediately breaks user trust.

| Framework concept  | Agricultural trade | Remote mental health | Art / collectibles  |
| ------------------ | ------------------ | -------------------- | ------------------- |
| Participant Type A | Exporter           | Practitioner         | Gallery / Seller    |
| Participant Type B | Importer           | Client               | Collector / Buyer   |
| Participant Type C | Service Provider   | Referral Partner     | Appraiser / Shipper |
| Handoff Artifact   | Deal Brief         | Plan of Care         | Acquisition Brief   |
| Match              | Trade Match        | Care Match           | Collection Match    |
| Deal               | Deal               | Engagement           | Acquisition         |
| Knowledge Q&A      | Trade Advisor      | Clinical Resource    | Market Intelligence |

The `MarketDefinition` already configures participant types and the Handoff Artifact name — extending it with a `ui_labels` section is a natural, low-cost addition.

**2. Language translation (framework wiring, LLM-assisted)**

The participant sees the interface in their language. This is a separate axis from terminology — a Filipino buyer sees the UI in Filipino regardless of whether the vertical calls it a "Deal Brief" or a "Trade Summary."

For **UI chrome** (buttons, labels, navigation), translation is an admin-time action, not a runtime service:
- The framework ships English locale files with generic keys
- Admin clicks "Add Filipino" → the system sends the English locale file + vertical context to the LLM → receives a complete translated locale file in one call
- The sponsor reviews, adjusts domain-specific terms, and saves
- From that point on, translations are served statically at zero incremental cost
- When the framework adds new UI strings, the admin clicks "Update translations" and the LLM fills in only the gaps

For **dynamic participant content** (profile descriptions, listing text, chat messages), runtime LLM translation is appropriate because the content can't be pre-translated:
- The Intelligence Slot's `translate` service handles this, with task-level routing for specialised languages (e.g., Amharic → specialised model)
- Results are cached per content hash — translate once on first view, serve from cache thereafter

Standard i18n infrastructure (`next-intl` or similar) handles the wiring. An admin string editor in the UI lets sponsors review and refine translations without touching code.

**3. Visual branding (framework tokens, vertical values)**

CSS custom properties — primary color, accent color, font family, border radius, spacing scale — exposed as a theme configuration. The admin uploads a logo, picks brand colors, and the entire UI re-skins without touching code. Structural customization (custom pages, domain-specific components) is the vertical's responsibility — the framework provides the component library; the vertical assembles its pages.

**Design principle:** A less-skilled developer should be able to get a branded, correctly-labelled, translated marketplace running by providing three artifacts: a `MarketDefinition` (with `ui_labels`), a locale file (LLM-generated, sponsor-reviewed), and a theme config — without forking the frontend.

### AI-Assisted Market Configuration (future capability)

The framework generalization work — MarketDefinition, dynamic schemas, Prompt Studio, Knowledge Slot, UI customization — creates a configuration surface large enough that new market sponsors face a "blank page" problem: they know their domain, but they don't know what fields to configure or how Cosolvent's abstractions map to their market.

An **AI assistant embedded in the admin interface** can bridge this gap. Rather than building a separate external wizard and a Configuration API, the AI assistant works inside the existing admin UI — pre-filling forms, suggesting schemas, and drafting prompts based on a conversational description of the sponsor's market.

**Four levels of configuration the AI can assist with:**

| Level                   | What's configured                                                            | AI role                    | Example                                                                                                     |
| ----------------------- | ---------------------------------------------------------------------------- | -------------------------- | ----------------------------------------------------------------------------------------------------------- |
| **1. MarketDefinition** | Participant types, UI labels, handoff artifact name                          | Generate from conversation | "Your participants are Exporters, Importers, and Freight Forwarders. The handoff artifact is a Deal Brief." |
| **2. Schema**           | Fields per participant type, Knowledge Slot metadata tags, aggregation rules | Suggest and pre-fill       | "Exporters should have origin_country, product_category, quality_grade, volume_tons, certifications"        |
| **3. Content**          | Knowledge Slot documents, domain chat prompts, locale translations, theme    | Draft for review           | "Here's a matching prompt for agricultural trade: 'You are a trade advisor specialising in...'"             |
| **4. Code**             | Custom components, vertical-specific business logic                          | Out of scope               | Requires a developer                                                                                        |

**Implementation approach — internal, not external:**

The AI assistant uses the same backend operations the admin UI forms already use. There is no separate Configuration API to build, maintain, or secure. If programmatic access is ever needed (e.g., for multi-instance automation), the internal operations can be extracted into a REST API at that point.

| Stage       | What                                                                                                             | When                                         |
| ----------- | ---------------------------------------------------------------------------------------------------------------- | -------------------------------------------- |
| **Stage 0** | Admin UI with manual forms for MarketDefinition, participant schemas, prompts, themes                            | Already on the roadmap (Phase 2, B1.4, B1.8) |
| **Stage 1** | AI assistant panel in admin — "Describe your market" → AI suggests MarketDefinition, schemas, prompts, UI labels | After Stage 0 is working                     |
| **Stage 2** | AI generates Knowledge Slot metadata schema, drafts domain-specific prompts, creates locale translations         | After Knowledge Slot is working              |
| **Stage 3** | If demand warrants, extract internal operations into a Configuration API for programmatic access                 | When multiple deployments need automation    |

**Implication for vertical packages (GPSim and others):**

With AI-assisted configuration, a vertical package is no longer a separate codebase — it becomes a **configuration template**: a saved MarketDefinition + schemas + prompts + Knowledge Slot content + theme + locale files. The AI assistant could store and share these as starting points: "Start from the Agricultural Trade template" or "Start from the Mental Health Services template." A sponsor begins with a template, then customises through the AI-assisted admin UI. This reduces the vertical from a code repository to a configuration artifact that the framework manages.

---

## 22. Data Model & Schema Evolution

### What exists now (from `init.sql`)

| Table                              | Purpose                                          | WP Alignment / Three-Layer Fit                                                            |
| ---------------------------------- | ------------------------------------------------ | ----------------------------------------------------------------------------------------- |
| `producers`                        | Farm/exporter profiles (20+ ag-specific columns) | Producer side only; domain-hardcoded. `ai_profile` conflates gallery and matching.        |
| `producer_files`                   | Asset metadata for producers                     | Has `privacy` field (`TEXT`, `'private'`/`'public'`). **Needs expansion to multi-level.** |
| `templates`                        | Profile templates                                | Existing, adequate                                                                        |
| `embeddings`                       | pgvector embeddings for producers                | Producer-only; limited metadata                                                           |
| `app_config`                       | Singleton LLM orchestration config               | Existing, adequate                                                                        |
| `documents`                        | Industry context document metadata               | Existing, adequate                                                                        |
| `system_prompts`                   | Prompt storage                                   | Existing but underutilised                                                                |
| `participants` (**new**)           | Generic participant store (JSONB)                | **Good start** — needs gallery/matching profile separation and service+frontend           |
| `participant_embeddings` (**new**) | Generic embeddings with JSONB metadata           | **Good start** — should carry dual embeddings (gallery + matching) or metadata flags      |

### Changes to existing tables for three-layer architecture

| Table                                  | Change                                                                                                                    | Purpose                                                                                           |
| -------------------------------------- | ------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| `producer_files` → `participant_files` | Rename; expand `privacy` from TEXT to an ENUM or constrained set: `public`, `gallery`, `match-only`, `ai-only`, `private` | Per-document privacy control (Section 4, Layer 3)                                                 |
| `producer_files` → `participant_files` | Add `ai_extractable BOOLEAN DEFAULT true`                                                                                 | Controls whether the AI may extract structured data from this document, independent of visibility |
| `producer_files` → `participant_files` | Add `extraction_target TEXT DEFAULT 'both'` (values: `gallery`, `matching`, `both`, `none`)                               | Controls which profile layer receives extracted information                                       |
| `participants`                         | Add `gallery_profile JSONB`                                                                                               | Curated, user-approved public representation (Layer 1)                                            |
| `participants`                         | Add `matching_profile JSONB`                                                                                              | AI-only deep profile including private signals (Layer 2)                                          |
| `participant_embeddings`               | Add `embedding_type TEXT DEFAULT 'matching'` (values: `gallery`, `matching`)                                              | Support dual embeddings — one for gallery browsing, one for deep matching                         |

### Tables and concepts still needed

| Missing Concept                   | Description                                                                                                                                                |
| --------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Listings**                      | Specific offerings with pricing, quantities, availability windows, quality specifications                                                                  |
| **Buyer profiles / requirements** | (Could use `participants` with `type='buyer'`)                                                                                                             |
| **Facilitator profiles**          | Service provider capability profiles (could use `participants` with type-specific `data` JSONB — e.g., `type='customs_broker'`, `type='logistics'`)        |
| **Deals**                         | In-progress transactions between principals, with structured requirements, deal stage, and role slots for facilitators (Section 3.3)                       |
| **Deal Role Slots**               | Per-deal facilitator requirements: role type, status (`needed`, `searching`, `proposed`, `confirmed`, `not-needed`), and reference to attached facilitator |
| **Deal Participants**             | Junction table linking deals to all involved participants (principals + facilitators) with their role in the deal                                          |
| **Transactions**                  | Completed deals with prices, ratings, outcomes                                                                                                             |
| **User Agents**                   | Agent configuration (negotiation parameters, authority levels, persona)                                                                                    |
| **Interaction Logs**              | User search history, match views, rejections, conversation history                                                                                         |
| **Disputes**                      | Dispute records with evidence, status, and resolution                                                                                                      |
| **Groups / Cooperatives**         | Collective participant entities with membership roster, manager role, aggregated profiles, supply schedules, and order allocation tracking (Section 13)    |
| **Regulatory Rules**              | Jurisdiction-specific compliance requirements                                                                                                              |
| **Trust Scores**                  | Computed reputation scores and verification status                                                                                                         |
| **Market Physics Scorecards**     | Per-vertical assessment of market characteristics and challenges                                                                                           |
| **Price Comparables**             | Historical transaction data for fair-value estimation                                                                                                      |
| **Notifications**                 | Alert queue for agent escalations, match alerts, deal updates                                                                                              |
| **Privacy Audit Log**             | Track changes to document privacy settings for compliance and user transparency                                                                            |

> **Note:** The previous roadmap listed "Confidential Vaults" as a missing table. Under the three-layer architecture, this is no longer a separate table — it is operationally implemented through the `matching_profile` JSONB column on `participants` plus documents with `ai-only` or `match-only` privacy. The vault is an access pattern, not a storage concept.

---

## 23. Frontend & UX Gaps

### What the whitepaper says (Chapter 30)

The Interface Layer includes: chat interfaces on key pages (context-aware, with human escalation), background agents, and mobile interfaces (low-bandwidth, voice-first, SMS/USSD fallback, offline capability).

### Current state

- `page.tsx` (landing) renders: `HeroSection`, `WhyPgpSection`, `LiveOfferingsSection`, `ProducersSection`, `HowItWorksSection` — marketing-oriented, producer-facing.
- `(protected)/admin/page.tsx` and `(protected)/user/page.tsx` — minimal content.
- `chatbot/chatbot.tsx` — floating widget, general Q&A against industry context.

### Required changes

- **Buyer dashboard:** Search, saved searches, match notifications, deal tracking, agent configuration.
- **Seller dashboard:** Listing management, incoming inquiries, agent configuration, analytics, reputation view.
- **Facilitator dashboard:** Deal feed (deals matching the facilitator's capabilities), active engagements, capacity management, and performance analytics.
- **Deal assembly view:** When a buyer-seller match progresses to deal structuring, both principals see a deal view showing:
  - Deal parameters (product, route, volume, timeline, value)
  - Role slots with status indicators (needed / searching / proposed / confirmed / not-needed)
  - AI-recommended facilitators for open slots, with gallery-level profiles and match rationale
  - Attached facilitators with contact/coordination information
- **Profile management:**
  - **Gallery profile editor:** Users review, edit, and approve what appears in their public profile. Clear preview of how their gallery card looks to other users.
  - **Document privacy manager:** A dedicated view showing all uploaded documents with their current privacy settings. Click-to-edit privacy levels (`public`, `gallery`, `match-only`, `ai-only`, `private`). Visual indicators showing which documents feed the gallery vs. matching profile.
  - **Matching profile transparency:** Users should be able to see *what the AI knows about them* (without revealing how it uses that information in specific matches). This builds platform trust.
- **Admin dashboard:** Market Physics Scorecard visualization, dynamic field builder, prompt editor, MCP slot management, user verification queue. Should include **facilitator type management** — admin defines which facilitator categories exist for this marketplace vertical.
- **Rich match cards:** Match results should display AI-generated rationales, fair-value estimates (when available), trust scores, and key compatibility factors — not just ranked IDs. Rationale text must respect privacy boundaries.
- **Progressive disclosure:** Initial match results show minimal information (gallery-level); users can "unlock" more detail as they progress through trust levels — with each unlock requiring the counterparty's consent to share.
- **Mobile-first design:** The whitepaper's emphasis on developing-market participants requires responsive, low-bandwidth-friendly layouts and eventual voice/SMS interfaces.

---

## 24. Infrastructure & Operations

### Current state

The infrastructure (Docker Compose with Postgres/pgvector, Redis, RabbitMQ, MinIO, Nginx) is well-designed for the current scope.

### Required changes for whitepaper alignment

- **Notification service** — email, SMS, push — for agent escalations, match alerts, deal updates.
- **Scheduled job runner** — for periodic tasks: synthetic bootstrapping scans, reputation recalculation, preference evolution analysis, predictive risk scoring.
- **Vector database scaling** — monitor pgvector performance as embedding volumes grow with bidirectional profiles, multi-vector representations, and interaction logs. Consider HNSW indexing (available in pgvector) as an alternative to IVFFlat for better recall.
- **Multi-tenancy** — the whitepaper envisions Cosolvent as applicable across verticals. The current implementation needs tenant isolation (or at least a clear "vertical" scoping mechanism).
- **API gateway** — rate limiting, API keys, usage tracking as the platform exposes more services to external integrations (WhatsApp bots, SMS gateways, payment APIs, MCP servers).
- **Encryption at rest** — required for the confidential data vault (Module 2).

---

## 25. Intervention Matrix Coverage Analysis

The whitepaper's Intervention Matrix (Chapter 27) maps every engineering intervention to the challenges it addresses. Current Cosolvent coverage against the AI columns:

| Challenge               | AI Matching                    | AI Trusted Intermediary   | AI Input Translation         | AI Memory                        |
| ----------------------- | ------------------------------ | ------------------------- | ---------------------------- | -------------------------------- |
| **Opacity**             | ⚠️ Partial (basic search works) | ❌ Missing                 | ❌ Placeholder only           | ⚠️ Partial (industry context RAG) |
| **Geographic Distance** | ⚠️ No geo-awareness             | ❌ Missing                 | ❌ Placeholder only           | ❌ No user memory                 |
| **Temporal Distance**   | ❌ No async agents              | ❌ Missing                 | ❌ Placeholder only           | ❌ No intent persistence          |
| **Information Density** | ⚠️ Single-signal embedding      | ❌ Missing                 | ❌ No multimodal capture      | ⚠️ Domain docs only               |
| **Cold Start**          | ❌ No bootstrapping             | ❌ Missing                 | ❌ No low-friction onboarding | ❌ No synthetic bootstrapping     |
| **Cognitive Bandwidth** | ❌ No curation/explanation      | ❌ Missing                 | ❌ No conversational UI       | ❌ No anticipation                |
| **Risk**                | ❌ No verification              | ❌ Missing                 | ❌ No doc verification        | ❌ No track record                |
| **Trust**               | ❌ No transparency              | ❌ Missing                 | ❌ —                          | ❌ No evidence-based trust        |
| **Regulatory Friction** | ❌ No compliance                | ❌ No compartmentalization | ❌ No compliance translation  | ❌ No compliance tracking         |
| **Fulfillment**         | ❌ No logistics                 | ❌ —                       | ❌ —                          | ❌ No performance tracking        |

**Key:** ✅ Addressed | ⚠️ Partially addressed | ❌ Not addressed

The matrix confirms that the most impactful near-term investments are in **enriching the existing matching engine** (moving ⚠️ to ✅) and **building the trust and memory modules** (converting large blocks of ❌ to at least ⚠️).

---

## 26. Prioritised Implementation Phases

Based on the whitepaper's emphasis, the three-layer architecture, the existing design docs, and the current codebase maturity, the following phasing is recommended.

### Two-Track Structure

After the shared foundation (Phases 1–2), the work naturally splits into two parallel tracks:

```
                    ┌─── Track A: Marketplace Depth ─────────────────────────┐
                    │   Deals, agents, pricing, intelligence                 │
Phase 1 → Phase 2 ─┤                                                        │
                    │                                                        │
                    └─── Track B: Platform Breadth ──────────────────────────┘
                        Accessibility, framework, simulation, global reach
```

**Why two tracks?** These represent structurally independent concerns:
- **Track A** deepens the marketplace — each step makes the platform *better at closing deals*. It adds deal workflows, agent intelligence, pricing, dispute resolution, and proactive outreach. This track is driven by **transaction sophistication**.
- **Track B** widens the platform — each step makes the platform *accessible to more markets and participants*. It adds input modalities, framework configurability, simulation, global infrastructure, and regulatory coverage. This track is driven by **reach and adaptability**.

The tracks share a common foundation (Phases 1–2) and have a small number of explicit cross-track dependencies (noted inline). Teams can resource and prioritize each track independently, coordinating only at those specific handoff points.

This parallelism is expected to persist as the platform matures — new depth features (smarter agents, richer deal types, more sophisticated pricing) do not block new breadth features (new input channels, new verticals, new geographies), and vice versa.

---

### Shared Foundation

#### Phase 1 — Three-Layer Foundation & Multilateral Matching
*Addresses: Sections 3 (Multilateral Marketplace), 4 (Three-Layer Architecture), Module 1; Chapters 2–5, 15–16*

| #    | Item                                                                                                                                                                                               | Dependency |
| ---- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |
| 1.0a | **Unified logging configuration** — shared logging module in `src/shared/` with environment-variable-controlled log level (`LOG_LEVEL`), consistent format. All services import from here.         | None       |
| 1.0b | **Replace `print()` with `logger`** — three files still use `print()` for error output (`index_service.py`, `embedding_service.py`, `search_route.py`). Convert to `logger.error()`.               | 1.0a       |
| 1.0c | **Structured JSON logging** — add a JSON formatter so each log entry is a parseable object with `timestamp`, `service`, `level`, `message`, and extra fields. Enables `docker compose logs \| jq`. | 1.0a       |
| 1.0d | **Request correlation IDs** — FastAPI middleware generates a UUID per incoming request, injected into logging context via `contextvars`. Passed as header on inter-service calls.                  | 1.0a       |
| 1.1  | Activate the `participants` / `participant_embeddings` tables with service routes and CRUD — supporting all participant types (sellers, buyers, facilitators)                                      | None       |
| 1.2  | Add `gallery_profile` and `matching_profile` JSONB columns to `participants`; separate the data paths                                                                                              | 1.1        |
| 1.3  | Expand `producer_files.privacy` to multi-level (`public`, `gallery`, `match-only`, `ai-only`, `private`); add `ai_extractable` and `extraction_target` columns. Rename to `participant_files`      | 1.1        |
| 1.4  | Build the document privacy management UI (upload with privacy selection, edit privacy after upload)                                                                                                | 1.3        |
| 1.5  | Build buyer/importer registration flow (using `participants` with `type='buyer'`)                                                                                                                  | 1.1        |
| 1.6  | Build facilitator/service-provider registration flow (using `participants` with facilitator types)                                                                                                 | 1.1        |
| 1.7  | Extend `search_service` for bidirectional matching; implement gallery search + participant-to-participant match search                                                                             | 1.2        |
| 1.8  | Enrich embedding input with multi-signal structured templates (type-aware — different templates for principals vs. facilitators)                                                                   | 1.2        |
| 1.9  | Add match rationale generation (LLM-generated "why this match" — privacy-respecting)                                                                                                               | 1.7        |
| 1.10 | Add a `listings` data model with pricing, availability, quantity, quality fields                                                                                                                   | 1.1        |
| 1.11 | Build buyer-side frontend views (dashboard, search, gallery browse, match results with rationale cards)                                                                                            | 1.5, 1.9   |
| 1.12 | Build gallery profile editor (user reviews/approves what appears publicly)                                                                                                                         | 1.2, 1.4   |

#### Phase 2 — Trust, Transparency & Admin Control
*Addresses: Modules 2 (partial), 6; Chapters 6, 28–29; Design docs*

| #    | Item                                                                                                                                                                                                                                | Dependency    |
| ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| 2.1  | Implement the admin UI for LLM configuration (Intelligence Slot) — including multi-provider registration, task-level routing rules, and model health monitoring                                                                     | None          |
| 2.2  | Build the Prompt Studio (admin-managed prompts stored in `system_prompts`) — with optional prompt-to-model binding and fallback chain configuration                                                                                 | None          |
| 2.3  | Extend `ClientName` and `LLMClient` to support multiple provider types (HuggingFace, Ollama, direct API) beyond OpenRouter                                                                                                          | 2.1           |
| 2.4  | Implement participant verification pipeline (document analysis, consistency checking)                                                                                                                                               | 1.1           |
| 2.5  | Build reputation/trust score model (tracking transaction outcomes, response times, dispute rates)                                                                                                                                   | 1.9           |
| 2.6  | Implement progressive trust stages in the frontend (info visibility + document disclosure gated by trust level, tied to per-document privacy)                                                                                       | 2.4, 2.5, 1.4 |
| 2.7  | Add transparent matching — surface AI reasoning factors with each match result (privacy-respecting)                                                                                                                                 | 1.8           |
| 2.8  | Build privacy-aware extraction routing (document privacy setting → profile layer routing; re-routing on privacy change)                                                                                                             | 1.3           |
| 2.9  | Add privacy audit log (track all changes to document privacy settings for compliance)                                                                                                                                               | 1.3           |
| 2.10 | **LLM call observability** — structured logging for every LLM call: model, prompt/completion token counts, latency_ms, cost estimate, service_name, success/failure. Foundation for cost monitoring and debugging matching quality. | 1.0c, 2.1     |

> **After Phase 2, the two tracks diverge. Items below use the prefix `A` (Track A) or `B` (Track B) to identify their track. Cross-track dependencies are marked with ⇄.**

---

### Track A — Marketplace Depth

*Makes the platform better at facilitating deals to the point of handoff (Section 3.6). Adds deal structure, communication channels, agent intelligence, the Handoff Artifact, and — in later phases — pricing intelligence and dispute resolution.*

#### A1 — Deals, Facilitators & Memory
*Addresses: Sections 3.3–3.4 (Deals, Facilitators), Modules 4, 5; Chapters 17, 19*

| #     | Item                                                                                                                                                                                                                                               | Dependency  |
| ----- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------- |
| A1.1  | Add user interaction logging (search history, match views, rejections with reasons)                                                                                                                                                                | Phase 1     |
| A1.2  | Build preference evolution analysis (LLM-driven pattern detection over interaction history)                                                                                                                                                        | A1.1        |
| A1.3  | Implement anticipatory matching notifications (new listings matching inferred needs)                                                                                                                                                               | A1.2        |
| A1.4  | **Build the Deal entity** — data model with principals, requirements, stage tracking, and role slots for facilitators                                                                                                                              | Phase 1     |
| A1.5  | **Build deal-triggered facilitator search** — analyze deal requirements, determine needed roles, search facilitator profiles                                                                                                                       | A1.4, 1.6   |
| A1.6  | **Build deal assembly UI** — role slot visualization, facilitator recommendations, attachment workflow                                                                                                                                             | A1.4, A1.5  |
| A1.7  | **Build facilitator dashboard** — deal feed matching capabilities, active engagements, capacity management                                                                                                                                         | A1.4, 1.6   |
| A1.8  | Build the User Agent entity and configuration model (negotiation params, authority levels, persona)                                                                                                                                                | Phase 2     |
| A1.9  | Build asynchronous conversation engine (multi-turn, state-persisted, time-zone-aware)                                                                                                                                                              | A1.8        |
| A1.10 | Implement deal progression workflow (inquiry → match introduction → conversation → deal assembly → **Handoff Artifact generation**)                                                                                                                | A1.9, A1.4  |
| A1.11 | **Build Handoff Artifact generator** — assembles curated output from profiles, conversation, shared docs, facilitator recs, regulatory flags; template is admin-configurable per vertical (Section 3.6, connects to Slots Architecture Section 21) | A1.6, A1.10 |
| A1.12 | Build notification service (email, SMS, push) ⇄ *Also used by Track B (B1.6)*                                                                                                                                                                      | None        |

#### A2 — Pricing, Aggregation & Market Intelligence
*Addresses: Modules 7, 8 (partial); Chapters 18, 22, 25–26. Note: These items extend the platform beyond the core handoff model. Fair-value estimation enriches the Handoff Artifact with pricing context; disputes and risk scoring are relevant only if/when the platform evolves toward in-platform execution for specific verticals.*

| #     | Item                                                                                                                                                                                                              | Dependency                  |
| ----- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------- |
| A2.1  | Add transaction history data model (prices, dates, quality attributes, ratings, outcomes)                                                                                                                         | 1.6                         |
| A2.2  | Build fair-value estimation service (comparable analysis, confidence-banded estimates)                                                                                                                            | A2.1                        |
| A2.3  | Integrate pricing into match results                                                                                                                                                                              | A2.2, 1.5                   |
| A2.4a | **Collective Participant Tier 1:** Add `group` participant type with membership roster, manager role, manual collective profile; group participates in matching and deals as a single entity (Section 13, Tier 1) | 1.1                         |
| A2.4b | **Collective Participant Tier 2:** Member data submission via low-bandwidth channels, automated profile aggregation from member data, supply schedule computation, order allocation tracking (Section 13, Tier 2) | A2.4a, B1.6 ⇄ *Cross-track* |
| A2.4c | **Collective Participant Tier 3:** Expose framework hooks for vertical-specific cooperative management — revenue distribution, governance, seasonal planning, certification (Section 13, Tier 3)                  | A2.4b                       |
| A2.5  | Implement proactive outreach generation (LLM-crafted messages when new matches appear)                                                                                                                            | A1.3                        |
| A2.6  | Build dispute data model and AI triage system                                                                                                                                                                     | Phase 2                     |
| A2.7  | Implement predictive risk scoring on in-progress deals                                                                                                                                                            | A2.6, A2.1                  |

---

### Track B — Platform Breadth

*Makes the platform accessible to more markets and participants. Adds input modalities, framework configurability, simulation, and global infrastructure.*

#### B1 — Accessibility, Multimodal Input & Framework
*Addresses: Module 3; Chapters 21, 30; Design docs (Slots Architecture)*

| #    | Item                                                                                                                                                                                      | Dependency                  |
| ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------- |
| B1.1 | Replace `image_to_text` placeholder with working VLM integration                                                                                                                          | None                        |
| B1.2 | Replace `speech_to_text` placeholder with working STT integration (Whisper or equivalent)                                                                                                 | None                        |
| B1.3 | Build natural-language listing creation flow (voice/text → structured listing)                                                                                                            | B1.1, B1.2                  |
| B1.4 | Implement dynamic participant schemas (admin-defined fields via field builder UI)                                                                                                         | Phase 2                     |
| B1.5 | Implement MCP client for external data source/tool connectivity                                                                                                                           | Phase 2                     |
| B1.6 | Plan WhatsApp/SMS/USSD interface layer                                                                                                                                                    | B1.3, A1.12 ⇄ *Cross-track* |
| B1.7 | Build Market Physics Scorecard model and diagnostic tool                                                                                                                                  | None                        |
| B1.8 | Build the UI customization layer: `MarketDefinition.ui_labels` (terminology), i18n wiring (locale files + admin string editor), theme tokens (CSS custom properties + admin theme config) | B1.4                        |

#### B2 — ClientSynth Integration, Digital Twins & Global Scale
*Addresses: Chapters 26, 33–35; Regulatory and fulfillment coverage*

| #    | Item                                                                                                                                                                                                                                    | Dependency |
| ---- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |
| B2.1 | Define Cosolvent ↔ ClientSynth API contract for synthetic participant generation                                                                                                                                                        | B1.4       |
| B2.2 | Build synthetic mode (clearly labelled synthetic participants for testing/demo)                                                                                                                                                         | B2.1       |
| B2.3 | Build Digital Twin simulation harness (Cosolvent + ClientSynth + physics parameters)                                                                                                                                                    | B2.2, B1.7 |
| B2.4 | Add geolocation data and logistics estimation service                                                                                                                                                                                   | None       |
| B2.5 | Build regulatory context module and compliance checklist generator                                                                                                                                                                      | B1.5       |
| B2.6 | *(Future expansion)* Implement fulfillment and settlement integration (escrow, LOC interfaces) — vertical-specific; only relevant for deployments that evolve beyond handoff to in-platform execution (Section 3.6)                     | B2.4       |
| B2.7 | Add multi-tenancy for cross-vertical deployment                                                                                                                                                                                         | B1.4       |
| B2.8 | *(Future capability)* AI-assisted market configuration — embed an AI assistant in the admin UI that generates MarketDefinition, suggests schemas, drafts prompts and locale files from a conversational market description (Section 21) | B1.4, B1.8 |

---

### Cross-Track Dependencies

The two tracks are largely independent, but share these specific handoff points:

| Item                     | Track | Depends on                   | Track | Notes                                                                                                                                                                       |
| ------------------------ | ----- | ---------------------------- | ----- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| B1.6 (WhatsApp/SMS/USSD) | B     | A1.12 (Notification service) | A     | The notification service infrastructure is needed for message delivery channels. If Track B reaches this point first, A1.12 can be pulled forward — it has no dependencies. |

As the platform matures, additional cross-track dependencies may emerge (e.g., Digital Twin simulations may want to model pricing dynamics, linking B2.3 to A2.2). These should be tracked and managed as coordination points rather than blocking dependencies.

---

## Cross-Cutting Principles

Across all phases, these principles from the whitepaper should guide implementation. They are grouped to tell a coherent story — from why thin markets require a different approach, through what the platform does and how information flows, to how the team builds it.

#### A — Why thin markets are different

1. **Structural desire must exist.** AI can accelerate discovery of latent demand but cannot create demand that does not exist. *(Chapter 2)*
2. **Test with thin-market dynamics.** Validate against scenarios with few participants, infrequent transactions, and high stakes per transaction — not thick-market assumptions. *(Chapter 1)*
3. **Trust is the prerequisite, not a feature.** Every new capability should be evaluated through the lens of "does this increase or decrease participant willingness to engage?" *(Chapters 6, 28–29)*

#### B — What the platform does

4. **The framework defines the structure; the vertical defines the content.** Participant types, facilitator roles, handoff artifact templates, and matching logic are admin-configurable per deployment. The code never refers to "buyers" or "sellers" — it refers to participants with configurable types. *(Sections 3.6, 21)*
5. **Deals need more than two parties.** Real transactions in thin markets require facilitators — logistics, customs, inspection, finance. The platform must match deals to service providers, not just buyers to sellers. *(Section 3)*
6. **The platform's job is to get parties to the table, not to run the table.** V1 ends at a Handoff Artifact — a structured package that downstream professionals can act on. Full transaction execution is a future, vertical-specific expansion. *(Section 3.6)*

#### C — How information flows

7. **Privacy is a prerequisite.** Fewer participants means individual data is more identifiable and leaks are more damaging. *(Chapter 29)*
8. **Gallery is for discovery, matching is for depth.** Public profiles should be polished and user-approved for browsing. Deep matching should draw on richer, privacy-controlled data that the user has explicitly opted into sharing with the AI. Never conflate the two. *(Section 4)*
9. **Users own their information boundaries.** Per-document privacy settings must be editable, understandable, and visible. The system must never use information beyond its designated privacy level. *(Section 4)*
10. **Communication is scoped, not open.** Participants communicate within match or deal contexts, not through general-purpose messaging. Context-scoped communication prevents spam, provides shared framing, and lets the AI participate meaningfully. *(Section 3.5)*
11. **Never destroy information through premature standardisation.** Preserve heterogeneity in profiles and listings; let AI handle the complexity. *(Chapter 15)*

#### D — How we implement it

12. **Design for cognitive bandwidth constraints.** Every UI and API should present curated, relevant subsets — not raw data dumps. *(Chapter 7)*
13. **Prompt-driven, not code-driven.** Business logic for matching, extraction, and negotiation should live in admin-managed prompts, not hardcoded Python/TypeScript. *(Design docs, Chapter 32)*

---

## Appendix: Whitepaper Chapter → Roadmap Section Cross-Reference

| WP Chapter | Title                                                                                                   | Roadmap Section(s) |
| ---------- | ------------------------------------------------------------------------------------------------------- | ------------------ |
| 1          | Defining Market Thickness                                                                               | 2, 25 (principles) |
| 2          | Desire to Exchange                                                                                      | 2, 25 (principles) |
| 3          | Arrangement of Counterparties                                                                           | 2, 3               |
| 4          | Business and Consumer Combinations                                                                      | 2                  |
| 5          | Theoretical Maximum Market Size                                                                         | 2, 12              |
| 6          | Existential Challenges (Risk, Trust, Regulation)                                                        | 9, 18              |
| 7          | Resistance Challenges (Info Density, Distance, Opacity, Cold Start, Cognitive, Fulfillment)             | 2, 4, 17, 19       |
| 8–13       | Traditional Engineering (Brokers, Market Makers, Storage, Standards, Geo Concentration, Clearinghouses) | 3, 19, 25          |
| 14         | Role of Memory                                                                                          | 8                  |
| 15         | Three Core AI Capabilities                                                                              | 4, 5, 6            |
| 16         | AI-Driven Matching                                                                                      | 4                  |
| 17         | AI as Institutional Memory                                                                              | 8                  |
| 18         | Dynamic Pricing and Valuation                                                                           | 10                 |
| 19         | Asynchronous Brokerage                                                                                  | 7                  |
| 20         | Trusted Intermediation and Information Synthesis                                                        | 5                  |
| 21         | Input Friction Reduction                                                                                | 6                  |
| 22         | User Aggregation                                                                                        | 12                 |
| 23         | Psychological Framing                                                                                   | 13                 |
| 24         | Dispute Resolution                                                                                      | 11                 |
| 25         | Sales and Business Development                                                                          | 14                 |
| 26         | Synthetic Market Bootstrapping                                                                          | 15                 |
| 27         | Intervention Matrix                                                                                     | 24                 |
| 28–29      | Trust in Thin Markets (AI-Enabled, Platform Trust)                                                      | 9                  |
| 30         | Tactical AI Stack                                                                                       | 22, 23             |
| 31         | DeeperPoint Vision                                                                                      | 1                  |
| 32         | Cosolvent Framework                                                                                     | 1, 20              |
| 33         | ClientSynth                                                                                             | 15                 |
| 34         | Digital Twins                                                                                           | 16                 |
| 35         | AI as Engineering Solution to Middle Powers Trade                                                       | 18                 |
| 36         | The Path Forward                                                                                        | 25                 |

---

*This roadmap will be updated as implementation progresses and as the whitepaper framework evolves.*

---

## Appendix A — Project Effort Estimate

> **Date:** February 2026
> **Scope:** Phase 1 + Phase 2 + A1 + B1 + B2 (excludes A2 and future-marked items B2.6, B2.8)

### Team Composition

| Person                                   | Role                                                                     | Effective contribution           |
| ---------------------------------------- | ------------------------------------------------------------------------ | -------------------------------- |
| **Mustafa**                              | Architect, vibe coder with team lead, reviewer, architecture decisions   | ~0.5 FTE on coding-adjacent work |
| **Team lead (Ethiopia)**                 | AI-assisted development lead, works with Mustafa in Opus/Gemini sessions | ~0.8 FTE                         |
| **Developer 2 (Ethiopia)**               | Parallel implementation                                                  | ~0.8 FTE                         |
| **Developer 3 (Ethiopia, if available)** | Parallel implementation                                                  | ~0.8 FTE                         |

**Effective team capacity:** ~2.0–2.9 FTE developer-equivalents

**Primary tools:** Opus 4.6 (or equivalent AI coding assistant), Gemini Ultra for architecture and analysis, VS Code, Docker Compose.

### AI-Assisted Coding Acceleration

With a state-of-the-art AI coding assistant, acceleration varies by task type:

| Task type                  | AI acceleration | Notes                                                                                         |
| -------------------------- | --------------- | --------------------------------------------------------------------------------------------- |
| Schema + CRUD + API routes | **3–5x**        | Boilerplate-heavy, well-understood patterns. AI generates 90% correct on first pass.          |
| UI components and pages    | **2–3x**        | AI generates solid starting points; iteration on layout/UX is still human judgment.           |
| Embedding/LLM integration  | **2–3x**        | Patterns exist, but prompt engineering and evaluation require human judgment.                 |
| Architecture + integration | **1.5–2x**      | AI helps write the code but the *decisions* are the bottleneck.                               |
| Testing + debugging        | **1.5–2x**      | AI generates test scaffolds well. Debugging integration issues across services is still slow. |

**Blended acceleration: roughly 2–3x.**

### Phase-by-Phase Estimate

| Phase                   | Items     | Nature                                                    | Raw effort (dev-weeks) | AI-assisted (dev-weeks) |
| ----------------------- | --------- | --------------------------------------------------------- | ---------------------- | ----------------------- |
| **Phase 1** (1.0a–1.12) | 16        | Schema, CRUD, search, UI, embeddings                      | 8–12                   | 3–5                     |
| **Phase 2** (2.1–2.10)  | 10        | Admin UI, trust model, LLM orchestration                  | 7–10                   | 3–4                     |
| **A1** (A1.1–A1.12)     | 12        | Deals, agents, conversation engine, Handoff Artifact      | 10–14                  | 4–6                     |
| **B1** (B1.1–B1.8)      | 8         | Multimodal, dynamic schemas, WhatsApp, i18n               | 7–10                   | 3–4                     |
| **B2** (B2.1–B2.7)      | 6 active  | ClientSynth integration, Digital Twin, geo, multi-tenancy | 6–9                    | 2–4                     |
| **Total**               | ~52 items |                                                           | 38–55                  | **15–23**               |

### Critical Path

Phases have structural dependencies:

```
Phase 1 (foundation — everything depends on this)
    │
    ▼
Phase 2 (trust, admin — depends on Phase 1)
    │
    ├───────────────────────┐
    ▼                       ▼
Track A: A1               Track B: B1 → B2
(Deals, Handoff)          (Multimodal, Framework, ClientSynth)
```

| Segment                       | Calendar time | Notes                                                                                                     |
| ----------------------------- | ------------- | --------------------------------------------------------------------------------------------------------- |
| **Phase 1**                   | 5–7 weeks     | 16 items, some parallelizable but schema work (1.1–1.3) gates most. Team establishing AI-coding workflow. |
| **Phase 2**                   | 4–5 weeks     | 10 items, can overlap with late Phase 1. Admin UI and trust model are moderately complex.                 |
| **A1** (parallel with B)      | 6–8 weeks     | Most complex phase. Deal entity, conversation engine, and Handoff Artifact are architecturally novel.     |
| **B1 + B2** (parallel with A) | 7–9 weeks     | Partially sequential (B2 depends on B1.4, B1.7). Can start B1.1/B1.2/B1.7 immediately.                    |

**Critical path:** Phase 1 → Phase 2 → max(A1, B1→B2) = 5–7 + 4–5 + 7–9 = **16–21 weeks**

### Reality Multiplier (1.3–1.5x)

Factors that add overhead beyond raw coding estimates:

- **Architecture decision bottleneck** — Mustafa is the architect, and design sessions produce essential decisions. Budget 2–4 hours/week for this. Cannot be parallelized or AI-accelerated.
- **Integration friction** — five microservices, Docker Compose, database migrations, inter-service API contracts. Typically works on the 5th try.
- **Ethiopia coordination** — Toronto (EST) to Addis Ababa (EAT, +8 hours). Limited real-time pairing window. Async handoffs introduce communication latency.
- **Learning curve** — the team built the initial drafts, but the three-layer architecture, gallery/matching split, deal model, and Handoff Artifact are new concepts requiring internalization.
- **Testing and stabilization** — each phase needs integration testing before the next can build on it reliably.

### Summary Estimates

| Scenario         | Calendar time  | Key assumptions                                                                                        |
| ---------------- | -------------- | ------------------------------------------------------------------------------------------------------ |
| **Optimistic**   | **4–5 months** | Team clicks immediately with AI workflow, minimal rework, Mustafa available 15+ hrs/week, 3 developers |
| **Realistic**    | **5–7 months** | Normal integration friction, some rework, weekly architecture sessions, 2–3 developers                 |
| **Conservative** | **7–9 months** | Significant Phase 1 rework, team learning curve, constrained availability, 2 developers                |

**Honest estimate: 5–7 months** → demo-able state by approximately **August–October 2026**.

### What Accelerates the Timeline

1. **Don't skip Phase 1 logging (1.0a–d).** Half a day of work that saves weeks of debugging downstream.
2. **Architecture sessions are highest-leverage.** Every decision documented saves the team days of dead-end exploration.
3. **Start B1.1, B1.2, B1.7 immediately** — they have no Phase 1 dependencies. Team makes progress while foundations are being laid.
4. **Use ClientSynth-generated data from week 1.** Manually generate a small synthetic population and import it. Makes every feature testable sooner.
5. **The Handoff Artifact (A1.11) is the demo.** Everything converges there — matching, deals, facilitators, profiles. A working Handoff Artifact is the compelling demo that powers founder conversations.

### What's Excluded from This Estimate

| Excluded item                                      | Why                                                                                                    |
| -------------------------------------------------- | ------------------------------------------------------------------------------------------------------ |
| **A2** (Pricing, Aggregation, Market Intelligence) | Cooperative/collective work, fair-value estimation, disputes. Important but not required for the demo. |
| **B2.6** (Fulfillment integration)                 | Marked as future expansion.                                                                            |
| **B2.8** (AI-assisted market config)               | Marked as future capability.                                                                           |
| **Production deployment**                          | Hosting, domain, SSL, monitoring, production database. Separate effort.                                |

### Parallel Workstream: Knowledge Slot Document Curation

Knowledge Slot content — the domain-specific documents that ground the AI's contextual understanding — can be curated **entirely in parallel** with framework development. This work requires no code changes and produces the corpus that makes the demo compelling.

**What the Knowledge Slot serves:**
1. **Contextual grounding for matching** — the AI needs domain knowledge to evaluate match quality (e.g., SHG Ethiopian Yirgacheffe vs. specialty-grade Kenyan AA serve different market segments)
2. **Conversational domain knowledge** — participants ask domain questions the AI must answer accurately, not hallucinate
3. **Handoff Artifact enrichment** — deal briefs reference real regulatory requirements, logistics considerations, quality standards

#### Document Metadata Schema

Define this schema *before* curating. Every document gets tagged on ingest:

| Field              | Purpose                         | Example values                                                                          |
| ------------------ | ------------------------------- | --------------------------------------------------------------------------------------- |
| `commodity`        | What product(s) this applies to | `coffee`, `grain`, `oilseeds`, `general`                                                |
| `document_type`    | What kind of information        | `regulation`, `standard`, `market_report`, `logistics`, `trade_finance`, `quality_spec` |
| `jurisdiction`     | Where this applies              | `EU`, `Ethiopia`, `Kenya`, `Indonesia`, `international`                                 |
| `topic`            | Specific subject area           | `phytosanitary`, `grading`, `incoterms`, `customs`, `certification`                     |
| `source_authority` | Who published this              | `FAO`, `ICO`, `EU Commission`, `ECX`                                                    |
| `currency_date`    | When this was current           | `2025-06`, `2024-12`                                                                    |
| `reliability`      | How much to trust this          | `authoritative`, `industry_consensus`, `advisory`                                       |

#### AI-Assisted Curation Workflow

| Phase                           | Activity                                                      | Tool                                                                                     | Effort        |
| ------------------------------- | ------------------------------------------------------------- | ---------------------------------------------------------------------------------------- | ------------- |
| **1. Source discovery**         | Generate comprehensive source maps per topic area             | Gemini Deep Research, Perplexity                                                         | 2–3 days      |
| **2. Acquisition & conversion** | Find, download, convert PDFs to clean markdown                | Marker (open source, complex PDFs), Docling (tables), Gemini 2.0 (contextual extraction) | 5–8 days      |
| **3. Synthesis & structuring**  | Create focused, template-based documents from source material | Gemini Ultra, Claude with source PDFs uploaded                                           | 5–8 days      |
| **4. Metadata tagging**         | Tag each document with the schema above                       | Semi-automated with AI                                                                   | 1–2 days      |
| **5. Validation & gap-filling** | Test corpus by asking real user questions; fill gaps          | NotebookLM (upload corpus, query across all docs)                                        | 3–5 days      |
|                                 | **Total**                                                     |                                                                                          | **2–4 weeks** |

#### Key Techniques

- **Chunk by topic, not by page.** A 50-page market report becomes 8–12 focused documents, each with clear metadata. Retrieval quality depends on this.
- **Write for the LLM, not for humans.** Clear, unambiguous, structured. Facts stated directly. No narrative filler.
- **Include "negative knowledge."** What *doesn't* work or *isn't* allowed is as valuable as what to do. Prevents the AI from suggesting impossible deals.
- **Date everything and flag volatility.** Every document needs `currency_date` and an indication of stability. Documents flagged `volatile: true` trigger re-validation.
- **Build iteratively from user questions.** After the initial corpus, the best gap-finder is the system itself — when the AI gives a bad answer, that's a document to create.

#### Key Sources (Agricultural Trade / GPSim Vertical)

| Source                                      | What it provides                                           | Access                 |
| ------------------------------------------- | ---------------------------------------------------------- | ---------------------- |
| ITC Trade Map (trademap.org)                | Trade flows, market access conditions                      | Free with registration |
| FAO (fao.org)                               | Agricultural standards, commodity profiles, country briefs | Free                   |
| International Coffee Organization (ico.org) | Coffee grading, market reports, trade statistics           | Free                   |
| EU Access2Markets (trade.ec.europa.eu)      | Import requirements by product and origin for EU           | Free                   |
| USDA FAS (fas.usda.gov)                     | GAIN reports — country agricultural market intelligence    | Free                   |
| Ethiopia Commodity Exchange (ecx.com.et)    | Ethiopian commodity grading, warehouse receipts            | Partially free         |
| ICC (iccwbo.org)                            | Incoterms 2020, trade finance rules (UCP 600)              | Some paid              |
| World Bank                                  | Trade logistics indicators, customs procedures             | Free                   |
| National standards bodies                   | Country-specific grading standards (KBS, ESA)              | Varies                 |

#### Target Output

An initial corpus of **80–150 focused, metadata-tagged documents** covering grading standards, trade regulations, logistics corridors, trade finance instruments, certifications, and market context for the primary commodity/corridor combinations. Sufficient to make the demo compelling and the matching contextually intelligent.

#### Timeline Relationship to Framework

```
Week 1 ─────────────────────────────────────────── Week 20+
│                                                        │
├── Knowledge Slot curation (Mustafa + AI tools) ────────┤  ← Parallel, no code dependency
│   Weeks 1–4: initial corpus                            │
│   Weeks 5+: iterative gap-filling from testing         │
│                                                        │
├── Phase 1 (team) ──► Phase 2 ──► A1 / B1 / B2 ────────┤  ← Framework development
│                                                        │
│                  Knowledge Slot content ready ──►      │
│                  loads into framework when RAG          │
│                  pipeline exists (Phase 2+)             │
```

